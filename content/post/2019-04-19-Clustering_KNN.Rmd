---
title: "Clasifiación"
author: "JLMR"
date: 2019-04-18T21:14:14-05:00
categories: ["R"]
tags: ["LDA", "KNN"]
mathjax : true
menu:
  main:
    name: Clustering
    weight: 18
---



```{r set-global-options, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = FALSE)   


```



```{r silent-packages, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
library(tidyverse)
library(ISLR)
library(foreign)
library(scales)
```


## Clustering.

Un escenario de análisis en el que tenemos una serie de características y deseamos clasificar las observaciones de acuerdo a su similitud corresponde con un típico problema de **CLUSTERING**. En especial podemos abordarlo desde la perspectiva de *unsupervised learning* (no hay variable dependiente natural que deseamos predecir, lo que  buscamos es clasificar.)

A diferencia de los otros enfoques (R Lineal (MCO), R Logística), en este método no estamos tratando de predecir una variable dependiente, más bien buscamos determinar a qué grupo pertenece cada observación.
Y por supuesto es posible determinar la precisión con la que hacemos la predicción de la categoría a la que pertenece una determinada oobservación.


## K-Nearest Neighbors 

Método no paramétrico. ie, no asume que los datos toman una forma funcional predeterminada.


Calcula la distancia de un punto x en el espacio (generalmente **Euclidiano**, no obstante  hay otras posibilidades para determinar la distancia como la similitud coseno) con el resto de las observaciones.

Un supuesto central de este algoritmo es que observaciones que son similares tenderan a localizarse cerca.



![](/img/knn.jpg)

##Teoría.



La clasificación es para variables categóricas por definición pero las variables explicativas (features) idealmente son  numéricas, este modelo no tiene un buen desempeño cuando usamos variables categóricas como insumo  o cuando el número  de dimensiones *p*, (var explicativas) es muy grande (p>3).


Un parámetro importante en la estimación de este modelo es el número  **K**  de observaciones que debemos considerar para determinar a qué categoría pertenece la observación sobre la que se hace la predicción. 

Una práctica común en términos empíricos es considerar $k =\sqrt(n)$. Donde  **n** es el número de observaciones del conjunto de datos de contraste.

Como parte de la aplicación de este modelo validaremos **la precisión** mediante la estrategia de contraste entre un conjunto de datos de entrenamiento (**train data set**), que esta integrado por la proporción de datos que usaremos para estimar el modelo  del total de los datos disponibles (generalmente $80\%$).  Y un conjunto de datos de validación (**test data set**,  la proporción restante de datos ej. $20\%$).

Para aplicar la estrategia de validación y determinar el nivel de precisión alcanzado por el modelo, necesitamos constrir una **matriz de contraste** que nos indica cuantos casos son clasificados correctamente y cuantos son clasificados de forma incorrecta.


![](/img/cfm.jpg)


Note los elementos de la diagonal (2, 4 )(son predicciones correctas.

Cuatro   indicadores  son de interés para la validación:


1. El **precisión score** que  mide la fracción de la predicción que fue correcta **respecto a todas** las categorías. (max. val 100). 

$$Precision score=\frac{tp}{tp+fp}$$ Donde **tp**. fracción de observaciones clasificadas correctamente (predicción positiva para  observación  positiva. Y **fp** falso positivo).
 la fracción de la predicción que fue correcta **respecto a todas** las categorías. (max. val 100). 
 

![](\img\precision.jpg)

2. El indicador de **sensitividad** (*recall*) que mide la fracción clasificada correctamente de entre los registros positivos unicamente. $$recall=\frac{tp}{tp+fn}$$

![](\img\sensitivity_recall.jpg)

3. El *F score*, este indicador considera los dos anteriores al estimar una media armómica no aritmética. Ya que es posible tener modelos con valores elevados del sensitividad (recall) y valores pequeños de **precisión**. Esta medida pondera ambos.
$$F1=\frac{2*recall*precision}{recall+ precision}$$


4. **Accuracy score ACS**, la fracción de observaciones clasificadas correctamente. Con valor máximo 1. 

Esta medida se calcula como la fracción de aciertos entre el valor de predicción y el observado  respecto al total de datos en la muestra. 

Entre el f1 el ACS, por definición tenemos que el $ACS>F1$ Así que en un escenario estricto de medición nos interesa el valor del F1  más que el ACS como medida de desempeño de modelo.  


En la práctica el uso de la medida de validación dependerá del problema estuduado (ej. de los costos de clasificar incorrectamente los datos.)



## Implementación:


### Ejemplo 1.

##### Descripción 

##### Clasificación de personas: 

Conisdere un escenario sobre  transacciones realizadas en una tienda departamental en el que se busca determinar el comportamiento de las personas a partir de algunas características de las transacciones  como el valor de compras y la ocupación de la persona.

Este es un problema de clasificación en el que buscamos determinar si la persona es hombre o mujer (variable target) con base en  dos variables explicativas el monto gastado en sus compras   y su ocupación.


**Implementación:**

#### Ver jupyter notebook. K-NN.ipynb.  

a) Estime el modelo con un parámetro **K=3** y genere la predicción para el sexo de la persona utilizando las variables: *Purchase* y *Occupation*. 

Para la estimación del modelo considere una proporción del $30 \%$ para separar la base de datos de entrenamiento (train) de la base de validación (test). Y un parametro $k=\sqrt(n)$ Donde n es el numero de observaciones del conjunto de datos de contraste (y_test).

b) Estime el nivel de precisión del modelo.(i.e.¿Cuál es el porcentaje de casos clasificados correctamente?  Genere la matriz de contrsate  y estime el score de precisión. 

c) Determine el valor de cluster óptimo. (ie. el valor de k , para el que el score de precisión es el mas alto.)

d) Grafique sus resultados.




### Ejemplo 2.



Diabetes entre la tribu Pima (Población en la región Sonora-Arizona).
Considere un escenario en el que nos  interesa clasificar un conjunto de 768 pacientes con la etiqueta 1: diganóstico diabetes) 0: No diabetes en función de un conjunot de carácteríssticas.

Ver jupyter notebook:
##K-NN2-Pimas.ipynb

a) Estime el modelo con un parámetro **K=3** y genere la predicción para el sexo de la persona utilizando las variables: *Purchase* y *Occupation*. 

Para la estimación del modelo considere una proporción del $20 \%$ para separar la base de datos de entrenamiento (train) de la base de validación (test). 

Y un parámetro $k=\sqrt(n)$ Donde n es el número de observaciones del conjunto de datos de contraste (y_test).

b) Estime el nivel de precisión del modelo.(i.e.¿Cuál es el porcentaje de casos clasificados correctamente?  Genere la matriz de contrsate  y estime el F-score, acurracy score, precision score  y recall score.

c) Determine el valor de cluster óptimo. (ie. el valor de k , para el que el score de precisión es el mas alto.)

d) Grafique sus resultados.


#### Tarea.


## Linear Discriminant Analysis LDA.


Una ventaja de este **método de clasificación** respecto a otros como por ejemplo Modelos de **regresión  logística** es que podemos aplicarlos a $k>2 target variables$. En el modelo de regresión logísitica generalmente nuestra variable target de predicción tenemos dos ategorias (i.e la variable dependiente es dicotómica),  si bien es posible estimar el modelo para k>2, la especificación logit  en esos casos suele no ser tan estable).    

El método de elección para esta tarea ($k>2$) es **LDA** 




tdl...

Inlcuir *Cross-Validation* ISL  Chp.5. after logistic.