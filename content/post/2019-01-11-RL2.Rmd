---
title: "RL-Simple"
author: "José Luis Manzanarees Rivera"
date: 2018-12-28T21:13:14-05:00
categories: ["R"]
tags: ["Regresión Lineal", "MCO", "regression"]
mathjax : true
menu:
  main:
    name: RL-Simple
    weight: 4
---



```{r set-global-options, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = FALSE)                     

```



```{r silent-packages, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
library(ggrepel)
library(tidyverse)
library(scales)
library(ggpubr)
library(wooldridge)
```


## Regresión Lineal simple. 


**Objetivo de la sesión:** Presentar el modelo de Regresión lineal. Orígenes del concepto de regresión, características y estructura del modelo, expresión matématica. 


*All models are wrong, but some are useful. Box (1979)*


En el curso estamos interesados en modelar relaciones estadísticas (estocásticas) no deterministas, esto es, en las variables análizadas tenemos cierto grado de incertidumbre. 


### Orígenes de la noción de regresión

La noción de Regresión lineal. ¿Qué entendemos por regresión?

A pesar de las multiples contribuciones y desarrollos recientes sobre la aplicación de este concepto en el contexto del análisis estadístico el desarrollo del fenómeno de Regresión se atribuye al antropólogo británico **Francis Galton** (primo de **Charles Darwin**)  

De acuerdo con Stigler en su libro [Statistics on the table](https://drive.google.com/file/d/1NgCTeIg4Tclt-TsKpHV_wmXvk4TY7dZ9/view?usp=sharing) *"The story is an exciting one involving, science, experiment, mathematics, simulation and one of the great thougth experiments of all times."* (Stigler, 1999)

De acuerdo con **Dalton** en su obra [Hereditary Genius 1869](https://drive.google.com/file/d/1Zd3ORNina7jKPXe176nhUNP3wRSElsMv/view?usp=sharing). La mezcla de caracteristicas genéticas a lo largo de la descendencia explica el grado de talento observado en los individuos.

Su trabajo aborda entre otros elementos como el talento se manifiesta através de las generaciones. Ej. los Bachs, (Johann Sebastian Bach) los Bernoulli, (Daniel Bernoulli ), etc.

Sus observaciones parecian indicar que el talento sistemáticamente tendia a disminuir a medida que se consieraba a los miembros de la familia más distantes, tanto hacia "arriba"  en el árbol genealógico como hacia "abajo". La observación se manifiesta incluso al referirnos a otras especies. 

Dalton: *"if a man breeds from strong,  well-shaped dogs, but of mixed pedigree, the puppies will be sometimes, but rarely, the equals of their parents. They will commonly be of a mongrel, nondescript type, because ancenstral peculiarities are apt to crop out in the offspring".*

*Definiciones*.

Regresión es el estudio de la distribucion condicional de $Y|x$ de la variable de respuesta **Y** dado un vector $pX1$ de variables predictivas. En el modelo de regresión lineal $$Y=\beta^T X+\epsilon$$ 

Definición preliminar sobre el concepto de regresión. 

$Y$ es condicionalmente independiente de $x$ dada una combinación lineal $\beta^Tx$ de las variables predictivas.

Básicamente estamos modelando una **relación de dependencia**. En este caso la variable dependiente es cuantitativa, no categórica, si bien los regresores o variables explicativas (independientes) pueden  ser de tipo categórico o numérico, (considerando que se realiza la codificación apropiada).

In statistics, regression analysis consists of techniques for modeling the relationship between a **dependent variable** (also called response variable) and **one or more independent variables** (also known as **explanatory** variables or predictors).

In regression, the dependent variable is modeled as a **function of independent variables**, corresponding regression parameters (coeficients), and a random error term which represents **variation in the dependent variable unexplained** by the function of the dependent variables and coeficients. 

In linear regression the dependent variable is modeled as a **linear function of a set of regression parameters** and a random error.

The parameters need to be estimated so that the model gives the  **"best fit"** to the data. The parameters are estimated based on predefined criterion.

The most commonly used criterion is the **least squares method**, but other criteria have also been used that will result in diferent estimators of the regression parameters.

If a regression model adequately reflects the **true relationship** between the response variable and independent variables, this model can be used for **predicting dependent variable**, identifying important independent variables, and establishing desired causal relationship between the response variable and independent variables.

**Recomendación** [Linear regression Analysis.Xin Yan, 2009](https://drive.google.com/file/d/1peEQsZpHYhGscI6PGUQJ5gCFrM59sT35/view?usp=sharing)

El proceso de modelar la relación entre la variable dependiente y las explicativas incluye la determinación de la **significancia estadística** esto es, el grado de confianza sobre que tanto la forma funcional utilizada reproduce la verdadera forma funcional que subyace a los datos.

El análisis de regresión es un proceso que permite **predecir** los valores de la variable de respuesta con base en los valores que toman las variables explicativas o indepedientes.

Este proceso se realiza mediante la estimación de los **parámetros** de la función lineal seleccionada y  a partir del criterio estadística de referencia. En el particular, OLE.  

Es una **técnica de estimación paramétrica**. En contraste regresiones de tipo no parametrico donde el objetivo no es estimar los parámetros de la función que describe la relación entre las variables del modelo.


## Característcas y utilidad de los modelos de regresión.

Uno de los rasgos de interés de la técnica de **regresión** desde la perspectiva de su aplicación es su capacidad para hacer **predicción** y su uso para hacer inferencia, por ejemplo cuando el objetivo es determinar  qué variables se relacionan con la variable de respuesta de interés o qué relación existe entre la variable dependiente y cada una de las variables explicativas. 

Desde la determinación de indicadores en el contexto del análisis de política públíca en áreas como sociología, salud, economía o bien cuestiones como  mortalidad por diabetes, migración y mercados laborales, el efecto de los gastos de camapaña sobre los resultados de votaciones, los efectos del presupuesto en educación sobre el desempeño educativo,etc,.

Para responder las preguntas de investigación de interés la formulación de un modelo (expresión  matématica de las relaciones entre las variables que nos interesan) es útil.

El énfasis en los modelos presentados en nuestro curso es en **datos no experimentales**,(Un tipo de datos común en ciencias sociales). Datos que no se generan mediante experimentos contralados sobre individuos, este ultimo tipo común en otras disciplinas como Biología, ciencias de la salud con los ensayos clínicos por ejemplo. 

##  Modelos y relación funcional entre variables.

Una forma de representar la relación entre dos variables es a través de un diagrama de dispersión. La siguiente gráfica presenta la realación entre dos variables años de educación y salario para una muestra de 526 individuos.

knitr::opts_chunk$set(fig.width=12, fig.height=8)

```{r, echo=FALSE,fig.width=8, fig.height=6, warning=FALSE, message = FALSE}
theme_set(theme_light())

data(wage1)
str(wage1)

ggplot(wage1,aes(educ,wage,colour = educ))+
  geom_point()+
  labs(title="Salario v.s Educación", x="Años de educación", y="Salario por hora (USD)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+ 
  scale_x_continuous(breaks = c(0, 6, 12,18))+
  labs(colour="Años")
```


A continuación se muestran posibles variables explicativas respecto a la variable dependiente salario, utilizando un scatter plot y una linea de tendencia generada mediante un modelo de regresión lineal. 


```{r, echo=FALSE, fig.width=10, fig.height=4,warning=FALSE, message = FALSE}
library(gridExtra)
data(wage1)

p1<-ggplot(wage1,aes(educ,wage))+
  geom_point(shape=1,color="blue")+
  labs(y="Salario por Hora (USD)", title="Años de Educación")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+ 
  scale_x_continuous(breaks = c(0, 6, 12,18))+
  stat_smooth(method=lm, se=FALSE, colour="red")


p2<-ggplot(wage1,aes(exper,wage))+
  geom_point(shape=1,color="blue")+
  labs(title="Años de experiencia")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(axis.title.y=element_blank())+
  stat_smooth(method=lm, se=FALSE, colour="red")



p3<-ggplot(wage1,aes(tenure,wage))+
  geom_point(shape=1,color="blue")+
  labs(title="Años con el empleador")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(axis.title.y=element_blank())+
  stat_smooth(method=lm, se=FALSE, colour="red")


grid.arrange(p1, p2, p3, nrow = 1)
```

Note que  para cada variable se observa una  de posible relación positiva de distinta magnitud. 

El siguiente ejemplo  presenta la relación de tres posibles variables explicativas para una variable dependiente denominada ventas. 

La gráfica  muestra la relación entre la variable dependiente ventas (expresada en miles) y los gastos en publicidad en tres diferentes medios  (variables independientes, expresada en miles de USD). n=200.

![](/img/r1.jpg)




Cada linea azul representa un modelo que puede usarse para predecir la variable **dependiente** **ventas** usando el procedimiento de mínimos cuadrados  (ordinary least squres **OLS**).

En términos  de notación la relación previa puede generalizarse como: 

$$Y=f(X)+\epsilon$$
Aquí $\epsilon$ representa un error aleatorio y $f()$ representa la forma funcional  que caracteriza la relación entre la variable dependiente y las variables explicativas.  Esta forma funcional se **asume lineal** en el modelo de regresión que estudiamos en este curso. 

Consideremos el siguiente ejemplo sobre el mercado laboral en el que se trata de analizar el efecto que determinantes como la educación, la experiencia o el nivel de entrenamiento tienen sobre la productividad.

En términos teóricos se espera que estos determinantes tengan un impacto sobre la productividad y considerado la relación positiva entre la productividad y el salario, se prevé un impacto en este último.

$$y=f(x_1, x_2, x_3)$$
$$ salario=f(educ, exper, training)$$

Donde: 

Salario: remuneración por hora.

educ: Años de educación formal.

exper: Años de experiencia en el trabajo. 

training: semanas dedicadas a entrenamiento.


Note el tipo de variables utilizadas, en este caso son numéricas (**cuantitativas** continuas), si bien en este curso el énfasis está en el uso de variables cuantitativas, es posible tambien incluir variables categóricas (*factors* que registran información **cualitativa** como sexo, la pertenencia a una región, etc.)

$$salario=\beta_0+\beta_1 educ +\beta_2 exper +\beta_3 training +\epsilon $$

![](/img/lm1.jpg)

**Note** en este caso que la relación verdadera entre las variables aunque se asume lineal puede tener otra forma funcional. Este aspecto es importante por que la precisión de las estimaciones realizadas depende de la selección de la forma funcional adecuada. 

**Note** La presencia de observaciones por arriba y algunas por abajo de la linea que expresa la relación funcional. Esto implica la presencia de errores respecto de medición entre la forma funcional y el valor real de los datos (estos errores son expresión de la naturaleza estocastica de las observaciones en la muestra). 

En términos formales la variación que observamos en la gráfica se puede expresar como: 

![](/img/lm2.jpg) 

La **precisión** en las predicciones obtenidas mediante un modelo, es decir la variación entre los valores estimados $\hat{Y} =f(X)$ y el valor real de la variable $Y$ se integra fundamentalmente por dos partes: 

La variación **reductible**, que se genera por la diferencia entre la forma funcional real y la forma funcional estimada por el modelo.

Y la variación **irreductible** atribuida a la naturaleza estocástica de las variables estudiadas que se ven influenciadas por un número infinito de factores mismos que no se capturan por el modelo. 


Note la importancia de la herramienta gráfica como  un paso preliminar a la construcción del modelo y en ayuda para conocer la relación posible entre las variables explicativas usadas como regresores y la variable dependiente que deseamos predecir o hacer inferencia.

Como primer paso una herramienta gráfica fundamental del análisis de regresión es la representación de los datos mediante un **scatter plot** bidimensional.

En algunos casos la relación entre la variable dependiente y las variables explicativas se basa en una teoría establecida con un grado elevado de concenso y precisión, no obstante en otros casos la relación entre variables se puede inferir a partir de su comportamiento, en cualquier caso las gráficas de dispersión son de suma importancia para explorar la relación entre las variables del modelo propuesto. 

Lectura **Recomendada** [Sanford Weisberg ,2010](https://drive.google.com/file/d/1pFd7mqYVSZ2qgNNIdZGUw51O1Cp5Y81P/view?usp=sharing)


## Actividad 2

Tiempo estimado: 25 min.


1.- Determine la relación que se observa por las variables en los siguientes escenarios. Indique el valor de **n** (tamaño de la muestra), Identifique la variable dependiente y la variable independiente.


a) Tasas de mortalidad por suicidio  y Google trends scores por entidad federativa. 

b) Tasa de mortalidad por cáncer de pulmón y proporción del gasto destinado a tabaco por hogar en México por entidad federativa.

c) Relación salario medio  y proporción mujeres/hombres en profesiones más comunes según disciplina del conocimiento.

d) Tasa de morbilidad por diabetes tipo II e índice de masa corporal promedio por entidad federativa. 

2.- Utilice la bases de datos College y comente sobre la estructura de los datos.

a) Explore la distribución (mediante un boxplot) de la variable  pago de colegiatura (*Outstate*)  según la institución es privada o pública (variable Private).

3.- Utilice la base de datos **birthwt** y comente sobre la estructura de los datos. 

a) Explore la  distribución de la variable peso (bwt) según la raza de la madre (variable race). Construya un histograma. 

b) Construya  un histograma para representar la ditribución de la variable **bwt** según  la madre fumó o no durante el embarazo (variable smoke).

## Sobre el proceso de modelado


El primer paso es seleccionar al forma funcional que vincula a la variable dependiente  con las explicativas. En esta caso el modelo que estudiaremos primero es cuando $f$ es lineal y bajo la estimación paramétrica.  

$$f(X)=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ...+\beta_p X_p $$

Este es un modelo lineal con $p+1$ parámetros a estimar, (uno por cada variable explicativa y el intercepto.)

El objetivo es estimar los parámetros con base en la forma funcional tal que se aproxime lo mas posible a la forma funcional real. Para lo cual un **método paramétrico clásico** es el de **minimos cuadrados** (OLS).

$$Y \approx \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ...+\beta_p X_p $$
Una desventaja potencial del este **método paramétrico** es que la pre-definición  de la forma funcional limita la precisión en comparación a estimaciones con métodos no paramétricos. 

La siguiente representación gráfica corresponde al caso de la forma funcional lineal estimada con métodos paramétricos mediante  MCO a), b) la forma funcional real y la estimación de un modelo no-parámetrico en c).  



![](/img/lm3.jpg)

La desventaja en métodos no-parámetricos es que su misma precisión implica cierta rigidez para su replica en muestras distintas o con observaciones nuevas.

El punto en la selección del modelo empleado para  representar la forma funcional es el **balance entre interpretabilidad y precisión** (entendiendo la precisión respecto a la flexibilidad para reproducir diversas formas funcionales no solo formas lineales como es el caso del método de RL por MCO.).

De hecho el modelo de regresión lineal es conveniente cuando buscamos **hacer inferencias**   dada su relativa facilidad de interpretación. 

En síntesis es importante tener en mente que hay un **trade off** entre el nivel de precisión en los estimados que pueden generarse por el modelo (el grado de sesgo *Bias* ej. Qué tanto nuestra forma funcional se aproxima a la forma funcional real que subyace a los datos) y la varianza, entendida esta como  la magnitud en la que $\hat{Y}$ cambia con la estimación de otras muestras o bases de datos.  


### Preguntas relevantes en las que el análisis de regresión lineal puede ser  útil.

Sea $$y = \beta_0 + \beta_1 x +\epsilon$$ un modelo lineal.


1.-Exsiste una relación entre las variables propuestas. Ej. salario y años de educación, peso del recien nacido y fumar durante el embarazo, ventas y gastos en publicidad para diferentes medios, flujos migratorios y características de los estados (USA), etc,.?

En este sentido nuestra meta es **proporcionar evidencia** de la existencia de una relación entre variable dependiente y explicativas.


2.- ¿Qué tan fuerte es la relación, entre las variables estudiadas. ¿Cuál es la magnitud de este grado de asociación en caso de existir?  

Nos permite esta asociación hacer predicciones  con un alto grado de exactitud? O la predicción es solo ligeramente mejor que una hecha de manera aleatoria.

3.- ¿De entre un conjunto de posibles variables explicativas ¿cuál  variable contribuye con mayor peso para el comportamiento de la  variable dependiente.

Para responder esta pregunta necesitamos determinar de los efectos individuales para cada variable.

4.¿Qué tan preciso es nuestro estimado del efecto individual que las variables explicativas tienen sobre la variable dependiente? Para un incremento de una unidad en las variables independientes ¿cuál es el efecto en al variale dependiente.

Suponiendo.

$$\Delta Y=\beta_1 \Delta x,  si \Delta \epsilon= 0$$
Donde $\beta_1$ es el parámetro que indica la **pendiente** en la relación entre y, x.



Note que $\Delta \epsilon=0$ es un supuesto que refleja  el hecho de que los otros factores, que de hecho no se miden, son constantes. 

5.-  ¿Cuál es el nivel de precisión en la predicción de la variable dependiente?

Para un nivel dado de las variables independientes ¿cuál es nuestra predicción de la variable dependiente?


6.- ¿Es la relación entre las variables lineal? Tal vez una combinación en las variables independientes tiene un mayor efecto en la variable dependiente que el incremento por separado en  cada una de las variables. 

Ej. La experiencia puede impactar las habilidades de un año a otro en forma creciente o tener un mayor imapcto considerando una combinación de educación y experiencia.  Este aspecto implica la estimación de *interacciones entre las variables*



Leer  Capítulo 3. [An Introduction to Statistical Learning](https://drive.google.com/file/d/1zaKc1XWvELsUgZrS32QdpHoM4-w0y7Qx/view?usp=sharing) Comentar en Diqus






### Términos clave 

**Least squares:** Noción atribuida a Gauss. Criterio para la estimación del modelo de regresión lineal.

### Referencias


Box, G. E. P. (1979). Robustness in the strategy of scientific model building. In R. Launer & G. Wilkinson (Eds.), Robustness in statistics (pp. 201–235). New York, NY: Academic Press.
