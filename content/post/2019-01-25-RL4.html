---
title: "RL-Hipótesis"
author: "José Luis Manzanarees Rivera"
date: 2019-01-25T21:11:11-05:00
categories: ["R"]
tags: ["Regresión Lineal", "MCO", "regression"]
mathjax : true
menu:
  main:
    name: RL-Hipótesis
    weight: 6
---



<div id="parametros-estimados-y-su-precision." class="section level3">
<h3>Parámetros estimados y su precisión.</h3>
<p>¿Qué tan preciso es un parámetro estimado mediante el modelo de regresión lineal?</p>
<p>Una manera de medir su precisión es mediante el cálculo del <strong>error estándar</strong> <strong>SE</strong> este nos indica el monto promedio en el que el parámetro <span class="math inline">\(\hat \beta\)</span> estimado difiere del valor poblacional <span class="math inline">\(\beta\)</span></p>
<p>Note que nos interesa determinar la precisión del parámetro muestral con relación al poblacional en este caso tomamos el ejemplo de la estimación de media muestral <span class="math inline">\(\hat \mu\)</span> con relación a su correspondiente valor poblacional <span class="math inline">\(\mu\)</span>.</p>
<p>El <em>SE</em> se basa en el concepto de la varianza <span class="math inline">\(var(\hat \mu)=SE(\hat \mu)=\frac{\sigma^2}{n}\)</span> Y esta dado por:</p>
<span class="math display" id="eq:se">\[\begin{align}
SE(\hat \beta_0)^2= \sigma^2 [\frac{\bar{1}}{n}+\frac{\bar{x}^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}]
\tag{1}
\end{align}\]</span>
<p><span class="math display">\[SE(\hat \beta_1)^2=  \frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}\]</span> Donde <span class="math inline">\(\sigma^2\)</span>=Var(<span class="math inline">\(\epsilon\)</span>).<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>El estimado de la desviación estandard <span class="math inline">\(\sigma\)</span> se denomina <em>Residual Standard Error</em> <strong>RSE</strong>. <span class="math inline">\(RSE=\sqrt{\frac {RSS}{(n-2)}}\)</span></p>
<p>Los <strong>Errores Standard</strong> son útiles en la estimación de los intervalos de confianza.</p>
<p>Un intervalo de confianza del <span class="math inline">\(95\%\)</span> se define como aquel rango tal que con el <span class="math inline">\(95\%\)</span> de probabilidad contiene el valor verdadero del parámetro.</p>
<p>El intervalo se compone por <strong>limites superior</strong> e <strong>inferior</strong> de la muestra de datos.</p>
<p>Para la regresión lineal el intervalo <span class="math inline">\(95\%\)</span> toma la especificación:</p>
<p><span class="math display">\[\hat \beta_1\pm2\cdot SE(\hat \beta_1)\]</span></p>
<p>Así por ejemplo el intervalo al <span class="math inline">\(95/%\)</span> de confienza indica que con un <span class="math inline">\(95\%\)</span> de confianza el verdadero valor de <span class="math inline">\(\beta\)</span> se encuentra en el rango definido por:</p>
<span class="math display" id="eq:ci">\[\begin{align}
[\hat \beta_1 -2*SE(\hat \beta_1), \beta_1 +2*SE(\hat \beta_1)]
\tag{2}
\end{align}\]</span>
<p>La misma lógica para estimar el intervalo para <span class="math inline">\(\hat \beta_0\)</span></p>
<p>Note que cuando el intervalo de confianza incluye <strong>0</strong> tenemos evidencia adicional de que el parámetro en cuestión no es estadísticamente significativo.</p>
<p>Quiz: Indentifique el intervalo de confianza de <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\hat \beta_0\)</span>, <span class="math inline">\(\hat \beta_1\)</span> para los ejemplos 1-3.</p>
</div>
<div id="prueba-de-hipotesis-y-significancia-estadistica-sobre-parametros" class="section level2">
<h2>Prueba de Hipótesis y significancia estadística sobre parámetros</h2>
<div id="valores-criticos-para-contraste.-relacion-entre-z-score-y-t-statistic." class="section level5">
<h5>Valores criticos para contraste. Relación entre <em>Z-score</em> y <em>t</em>-statistic.</h5>
<p>Para determinar si la relación entre la variable explicativa <span class="math inline">\(x\)</span> y la dependiente <span class="math inline">\(y\)</span> es estadisticamente significativa, la práctca estándard es probar <strong>la hipótesis Nula</strong> de que un coeficiente particular <span class="math inline">\(\beta_j=0\)</span>.</p>
<p>Comencemos por estudiar la relación que tiene la <strong>distribuciòn normal</strong> y la distribución <strong>t</strong> estas permiten comprender el criterio para hacer el contraste sobre la significancia estadística.</p>
<p>El contraste de la <strong>hipótesis nula</strong> es posible al utilizar el coeficiente estandard denominado <span class="math inline">\(Z-score:\)</span> denfinido como:</p>
<p><span class="math inline">\(z_j=\frac{\hat \beta_j}{\hat{\sigma}\sqrt{v_j}}\)</span></p>
<p>Donde <span class="math inline">\(v_j\)</span> es el <span class="math inline">\(j-esimo\)</span> elemento <span class="math inline">\((X^TX)^{-1}\)</span></p>
<p><a href="https://drive.google.com/file/d/13eW-lbR7YDSy50iNIJxTl4qdQM56F2UO/view?usp=sharing">Recomendación, ver secc. Linear Regression Models and Least Squares pag. 44</a></p>
<p>Recuerde que:</p>
<span class="math display" id="eq:rss1">\[\begin{align}
RSS(\beta)=\sum_{i=1}^N(y_i-f(x_i))^2
\tag{3}
\end{align}\]</span>
<p><span class="math display">\[=\sum_{i=1}^N(y_i-\beta_0 -\sum_{j=i}^p x_{ij}\beta_j)^2\]</span> Que es una función cuadrática en <em>p+1</em> parámetros</p>
<p>¿Cómo minimizamos <a href="#eq:rss1">(3)</a>?</p>
<p>Consideramos <strong>X</strong> como una matriz <strong>N</strong> x (p+1) con cada renglón como un vector de regresores con el valor 1 en la primer posición y con la variable <strong>y</strong> como el vector de dimensión <strong>N</strong> (variable dependiente).</p>
<p>Entonces podemos escribir la suma residual de cuadrados <strong>RSS</strong> como</p>
<span class="math display" id="eq:rss2">\[\begin{align}
RSS(\beta)=(y-X \beta)^T (y-X \beta)
\tag{4}
\end{align}\]</span>
<p>Al diferenciar con respecto a <span class="math inline">\(\beta\)</span> obtenemos:</p>
<span class="math display" id="eq:rss3">\[\begin{align}
\frac{\partial RSS}{\partial \beta}=2X^T (y-X \beta)
\tag{5}
\end{align}\]</span>
<p><span class="math display">\[\frac{\partial ^2 RSS}{\partial  \beta \partial \beta^T}=2X^T X\]</span></p>
<p>Fijamos la primera derivada =0.</p>
<span class="math display" id="eq:rss3">\[\begin{align}
X^T (y-X \beta)=0 
\tag{5}
\end{align}\]</span>
<p>Para obtener la solución única:</p>
<span class="math display" id="eq:rss4">\[\begin{align}
\hat \beta = (X^TX)^ {-1} X^T y  
\tag{6}
\end{align}\]</span>
<p>Donde <span class="math inline">\(\hat{\beta}\)</span> cumple con:</p>
<p><span class="math display">\[\hat \beta \sim N(\beta,(X^TX)^{-1} \sigma^2)\]</span></p>
<p>Con una matriz de <strong>varianza-covarianza</strong><span class="math display">\[var(\hat \beta )=(X^TX)^{-1} \sigma^2\]</span> y el valor de la varianza estimado como <span class="math display">\[\hat \sigma ^2=\frac{1}{N-p-1} \sum_{i=1}^N(y_i -\hat y_i)^2\]</span></p>
</div>
<div id="prueba-de-hipotesis." class="section level5">
<h5>Prueba de Hipótesis.</h5>
<p>Bajo la hipótesis nula <span class="math inline">\(\beta_j=0, z_j\)</span> se distribuye como <span class="math inline">\(t-N-p-1\)</span> una distribución <span class="math inline">\(t\)</span> con N-p-1 grados de libertad.</p>
<p>Considerando el parámetro muestral de la varianza, <span class="math inline">\(z_j\)</span> tendrá una <strong>distribución normal estandard</strong>. La diferencia entre los cuantiles de una distribución <span class="math inline">\(t\)</span> y la estandard normal, de hecho resulta infima, a medida que el tamaño muestral aumenta, <span class="math inline">\(N \rightarrow \infty\)</span> si bien utilizar los cuantiles de la distribución normal es un práctica común con muestras <span class="math inline">\(n \geqslant30\)</span>. <strong>Recordar Teorema de Limite central</strong></p>
<p>Si el estadístico <span class="math inline">\(t\)</span> estimado (en valor absoluto) &gt; <span class="math inline">\(t\)</span> crítico, el coeficiente <span class="math inline">\(\hat \beta\)</span> puede considerse como <strong>estadisticamente signficativo</strong> (y podemos rechazar la hipótesis <span class="math inline">\(H_0:\hat \beta=0\)</span>). La probabilidad de obtener por casualidad un valor como el estimado es ínfima (ej <span class="math inline">\(&lt; 5\%\)</span>).</p>
<p>La siguiente figura muestra esta relación.</p>
</div>
<div id="probabilidades-de-la-cola-en-la-distribucion-t-prz-z" class="section level5">
<h5>Probabilidades (de la cola en la distribución t) Pr(|Z| &gt; z)</h5>
<div class="figure">
<img src="/img/z-prob.jpg" />

</div>
<p>Note el valor de referencia del <span class="math inline">\(z-score\)</span> a medida que se incrementa el tamaño de muestra y la convergencia entre distribuciòn <span class="math inline">\(t\)</span></p>
<p>Note que <span class="math inline">\(z^{(1-\alpha)}\)</span> con el percentil <span class="math inline">\((1-\alpha)\)</span> de la distribcuiòn normal. ej. <span class="math inline">\(z^{(1-\alpha)}\)</span> con <span class="math inline">\(\alpha=0.025\)</span> ,<span class="math inline">\(z^{(1-0.025)}=1.96\)</span>, o bien <span class="math inline">\(z^{(1-0.05)}=1.645\)</span></p>
</div>
<div id="prueba-de-hipotesis-valores-criticos-y-areas-de-rechazo-de-la-hipotesis-nula." class="section level5">
<h5>Prueba de hipótesis, valores críticos y áreas de rechazo de la hipótesis nula.</h5>
<div class="figure">
<img src="/img/t.jpg" style="width:70.0%" />

</div>
<p>Definimos el cálculo del estadístico <span class="math inline">\(t\)</span> como <span class="math display">\[t=\frac{\hat \beta_1}{SE(\hat \beta_1)}\]</span></p>
<p>En consecuencia al calcular la probabilidad de que observemos un valor <span class="math inline">\(\geqslant |t|\)</span> podemos establecer la existencia de la relación estadística entre la variable dependiente y explicativa.</p>
<p>Esta probalbilidad la identificamos como <strong>p-value</strong> (ver resultados de la estimación ej. en R, Stata, etc.,)</p>
<p>Los valores usuales del <em>p-value</em> para el contraste de la hipótesis nula son $ 1% 5%$ <span class="math inline">\(10\%\)</span>.</p>
<pre><code>## 
## Call:
## lm(formula = lwage ~ educ, data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.21158 -0.36393 -0.07263  0.29712  1.52339 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.583773   0.097336   5.998 3.74e-09 ***
## educ        0.082744   0.007567  10.935  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4801 on 524 degrees of freedom
## Multiple R-squared:  0.1858, Adjusted R-squared:  0.1843 
## F-statistic: 119.6 on 1 and 524 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>## 
## Call:
## lm(formula = heightIn ~ ageYear, data = H)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3444 -1.7206 -0.3108  1.4369  7.9299 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  30.6580     2.3420   13.09   &lt;2e-16 ***
## ageYear       2.3009     0.1707   13.48   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.721 on 123 degrees of freedom
## Multiple R-squared:  0.5964, Adjusted R-squared:  0.5931 
## F-statistic: 181.8 on 1 and 123 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note en ambos casos que las probabilidades de observar los parámetros estimados si <span class="math inline">\(H_0\)</span> es verdad, son prácticamente cero!! Por lo tanto podemos concluir que <span class="math inline">\(\beta_0\neq0\)</span>, <span class="math inline">\(\beta_1\neq0\)</span><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
</div>
<div id="precision-del-modelo." class="section level3">
<h3>Precisión del modelo.</h3>
<p>Una vez que hemos rechazado la hipótesis nula, es importante cuantificar hasta que grado el modelo se ajusta a los datos, para lograr esto, dos estimados son considerados importantes:</p>
<p>El primero es el <em>Residual Standard Error</em> <strong>RSE</strong>.</p>
<span class="math display" id="eq:rse">\[\begin{align}
RSE=\sqrt{\frac {RSS}{(n-2)}} 
\tag{7}
\end{align}\]</span>
<p>El segundo es el estadístico <span class="math inline">\(R^2\)</span></p>
</div>
<div id="residual-standard-error-rse." class="section level3">
<h3>Residual Standard Error RSE.</h3>
<p>Recordemos que, asociado con cada observación tenemos en término de error <strong>e</strong>, por lo que no es posible predecir con total precisión <span class="math inline">\(Y\)</span> a partir de <span class="math inline">\(X\)</span>.</p>
<p>El <strong>RSE</strong> es un estimado de la desviación de <strong>e</strong>. Este indicador muestra el monto promedio en el que la variable dependiente se desvia de <strong>la verdadera linea de regresión</strong>.</p>
<p><span class="math display">\[RSE=\sqrt{\frac {RSS}{(n-2)}}\]</span> Recordemos que <span class="math display">\[RSS=\sum_{i=1}^{n}(y_i-\hat y_i)^2\]</span></p>
<p>En el caso del modelo sobre votaciones y gastos de campaña, por ejemplo el <span class="math inline">\(RSE=6.385\)</span> lo que implica que las votaciones en cada distrito difieren (se desvian) de la verdadera linea de regresión en promedio en <span class="math inline">\(6.385\%\)</span>, <strong>RSE=6.385</strong></p>
<p>Veamos el caso del modelo sobre ventas y gastos en publicidad (Ejemplo 3).</p>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV, data = ad)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3860 -1.9545 -0.1913  2.0671  7.2124 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
## TV          0.047537   0.002691   17.67   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.259 on 198 degrees of freedom
## Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 
## F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>El <span class="math inline">\(RSE=3.259\)</span> lo que implica que la ventas en promedio difieren de la linea verdadera de regresión en 3,259 unidades.</p>
<p>Note que el indicador RSE nos aporta una medida de precisión que depende del contexto, por ejemplo en este caso sabemos que el nivel de ventas medio es de 14,000 unidades por lo que la magnitud relativa de la desviación del es de <span class="math inline">\(23\%=3259/14000\)</span></p>
<p>Veamos el modelo sobre estatura y edad (ejemplo 2).</p>
<pre><code>## 
## Call:
## lm(formula = heightIn ~ ageYear, data = H)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3444 -1.7206 -0.3108  1.4369  7.9299 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  30.6580     2.3420   13.09   &lt;2e-16 ***
## ageYear       2.3009     0.1707   13.48   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.721 on 123 degrees of freedom
## Multiple R-squared:  0.5964, Adjusted R-squared:  0.5931 
## F-statistic: 181.8 on 1 and 123 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>El <strong>RSE</strong> estimado es <span class="math inline">\(2.721\)</span>, lo que se traduce en una desviación promedio de 2.7 pulgadas de la linea estimada de regresión.</p>
<p>En este caso la magnitud que representa la desviación respecto a la estatura media es de <span class="math inline">\(4.38\%= 2.72/62.06\)</span></p>
<p>En conclusión el <strong>RSE</strong> nos permite contar con una medida para contrastar la precisión (en el ajuste) entre varios modelos, esta <strong>expresado en las mismas unidades de la variable dependiente</strong>, es una medida absoluta, que puede ser útil para elegir el modelo más adecuado considerando los datos disponibles.</p>
<p>Una desventaja del RSE es que se expresa en las mismas unidades de <span class="math inline">\(Y\)</span> por lo que determinar cuando se tiene el mejor <strong>RSE</strong> entre modelos distintos, puede ser confuso.</p>
</div>
<div id="estadistico-r2" class="section level3">
<h3>Estadístico <span class="math inline">\(R^2\)</span></h3>
<p>El coeficiente de terminación <span class="math inline">\(R^2\)</span> mide la fracción de la varianza explicada. Permite una medida de ajuste alternativa. El <span class="math inline">\(R^2\)</span>, es una medida independiente de las unidades de medida de Y, expresada como proporción de la <strong>varianza explicada</strong> (siempre en el rango <span class="math inline">\(0 \leq R^2 \leq 1\)</span>).</p>
<p>De manera similar, el <em>adjusted</em> <span class="math inline">\(R^2\)</span> únicamente difiere en que “ajusta” por los grados de libertad en el modelo, si bien este prácticamente aporta la misma información al <span class="math inline">\(R^2\)</span> sin ajuste.</p>
<span class="math display" id="eq:r2">\[\begin{align}
R^2=\frac{TSS-RSS}{TSS}=1-\frac{RSS}{TSS}
\tag{8}
\end{align}\]</span>
<p>Donde <span class="math inline">\(TSS=\sum (y_i-\bar y)^2\)</span> Suma total de cuadrados (<em>Total Sum of Squares</em>)</p>
<p>El estadistico <span class="math inline">\(R^2\)</span> mide la proporción de la variación en <span class="math inline">\(Y\)</span> que es explicada por la regresión.</p>
<p>Note que el TSS mide la varianza total en la variable dependiente antes de estimar la regresión. mientras que <span class="math inline">\(\frac{RSS}{TSS}\)</span> indica la proporción de la variación que <strong>no es explicada</strong>.</p>
<p>Así, un valor cercano a cero en <span class="math inline">\(\frac{RSS}{TSS}\)</span> indica que la regresión explica una prporción importante de la variación de <span class="math inline">\(Y\)</span>.</p>
<p><strong>En consecuencia el valor del <span class="math inline">\(R^2 \longrightarrow1\)</span> será cercano a 1. Un indicativo de que el modelo captura una fracción importante de la variación.</strong></p>
<p>En el modelo sobre estatura y edad (ejemplo 2) el <span class="math inline">\(R^2=0.5964\)</span> por lo que prácticamente dos tercios de la variabilidad de <span class="math inline">\(Y\)</span> se explica por la regresión sobre la edad.</p>
<p>La magnitud del <span class="math inline">\(R^2\)</span> depende del problema estudiado y de la estructra del modelo y en general un valor cercano a 1 es considerado indicativo de un modelo robusto.</p>
<p>Por el otro lado un valor pequeño cercano a cero, indica la existencia de problemas con el modelo.</p>
<p>En aplicaciones en ciencias sociales por ejemplo, el modelo lineal es una aproximación muy general de la relación entre las variables por lo que los errores residuales debidos a las características no observadas son de gran magnitud lo que se refleja en valores de <span class="math inline">\(R^2\)</span>, generalmente por debajo de 1.</p>
</div>
</div>
<div id="actividad-4" class="section level2">
<h2>Actividad 4</h2>
<div id="ejercicio-1." class="section level4">
<h4>Ejercicio 1.</h4>
<p>Considere una <a href="http://gattonweb.uky.edu/sheather/book/docs/datasets/prostateAlldata.txt">muestra</a> de 97 pacientes en un estudio sobre cáncer de prostata. El objetivo es determinar la relación entre el estado del cáncer de prostata en individuos con diferentes niveles de riesgo y estado de diagnóstico y marcadores clínicos considerados como posibles determinantes.</p>
<p>La variable dependiente es un marcador para detectar la severidad, dada la presencia de la enfermedad: el antígeno prostático específico (<strong>lpsa</strong> log prostate specific antigen). Las variables explicativas son:</p>
<p>El volumen del tumor (<strong>lcavol</strong>: log cáncer volume), Peso de la próstata. (log prostate weight <strong>lweight</strong> ) y edad del paciente (<strong>age</strong>)</p>
<ol style="list-style-type: lower-alpha">
<li><p>Represente mediante un diagrama de dispersión la relación entre la variable dependiente y las explicativas.</p></li>
<li><p>Considerado la exploración visual sobre relación entre las variables, seleccione una variable explicativa para la estimación del modelo de regresión lineal simple y estime los parámetros <span class="math inline">\(\hat \beta_0, \hat \beta_1\)</span></p></li>
<li><p>Identifique el valor estimado del <strong>RSE</strong></p></li>
<li><p>A partir de los valores estimados del error estándard <strong>SE</strong> de los parámetros correspondientes al intercepto y la pendiente en el modelo lineal (<span class="math inline">\(\hat \beta_0, \hat \beta_1\)</span>), estime el intervalo de confianza del <span class="math inline">\(95\%\)</span> (límite superior e inferior).</p></li>
<li><p>Indique el valor del estadístico estimado sobre la precisión del modelo (<span class="math inline">\(R^2\)</span>) .</p></li>
</ol>
</div>
<div id="supuesto-de-varianza-constante-en-el-termino-de-error.-homocedasticidad." class="section level4">
<h4>Supuesto de varianza constante en el término de error. Homocedasticidad.</h4>
<p>Un supuesto importante sobre el comportamiento de la varianza del término de error <span class="math inline">\(\epsilon\)</span> dado el valor que toma la variable dependiente es que su <strong>varianza es constante</strong>. Var<span class="math inline">\((\epsilon|x)=\sigma^2\)</span> a este comportamiento se le denomina <strong>homocedasticidad</strong>. Y es un supuesto sobre la eficiencia que complementa las propiedades como estimadores no sesgados (<strong>BLUE</strong>) que se obtienen con la técnica de <strong>MCO</strong>.</p>
<p>Para ejemplificar consideremos el caso sobre el efecto del nivel educativo sobre el salario. Suponemos que <span class="math inline">\(E(\epsilon|educ)=0\)</span> lo que implica que <span class="math inline">\(E(salario|educ)=\beta_0+\beta_1 educ\)</span> y con el supuesto de homocedasticidad entonces Var<span class="math inline">\((\epsilon|educ)=\sigma^2\)</span> no depende del nivel de educación, lo que es sinónimo de Var<span class="math inline">\((salario|educ)=\sigma^2\)</span>.</p>
<p>Entonces, si bien en promedio el salario puede incrementarse a medida que el nivel de educación se incrementa, lo que nos interesa es que la tasa de crecimiento no varie, esto es que para cualquier nivel de educación la variación en el nivel salarial se mantenga constante. Escenario en este caso particular poco probable, por que es probable que entre los individuos con mayor nivel educativo se tenga una mayor variabilidad en los niveles salariales que entre grupos de individuos de bajos ingresos donde las opotunidades de empleo se ajustan generalmente en torno al salario mínimo, un escenario de mayor homogéneidad.</p>
<p>El supuesto de homocedasticidad es un hecho empírico sujeto a verificación. Ocurre cuando la Var<span class="math inline">\((y|x)\)</span> es una función de x.El no cumplimiento de este supuesto implica perdida de eficiencia en los estimados.</p>
<div class="figure">
<img src="/img/h.jpg" />

</div>
</div>
<div id="sintesis-de-supuestos-gauss-markov-para-el-modelo-de-regresion-simple." class="section level4">
<h4>Síntesis de Supuestos Gauss-Markov para el modelo de regresión simple.</h4>
<ul>
<li><p>Modelo lineal en los parámetros.</p></li>
<li><p>Muestra aleatoria.</p></li>
<li><p>Existe variación en la muestra que integra la variable explicativa. No existen relaciones exactas entre las variables explicativas. (Multicolinealidad).</p></li>
<li><p>Media condicional cero. El término de error <span class="math inline">\(\epsilon\)</span> tiene un valor esperado de cero dado cualquier valor de la variable explicativa <span class="math inline">\(E(\epsilon|x)=0\)</span></p></li>
<li><p>Homocedasticidad. El término de error <span class="math inline">\(\epsilon\)</span> tiene varianza constante.</p></li>
</ul>
</div>
<div id="tarea" class="section level3">
<h3>Tarea</h3>
<p>Leer sección <em>The Meaning of “Linear” Regression</em>. En Wooldridge (pag. 44). ¿A qué nos referimos cuando indicamos que se trata de un modelo lineal?</p>
<p>Leer linear Methods for regression. <a href="https://drive.google.com/file/d/13eW-lbR7YDSy50iNIJxTl4qdQM56F2UO/view?usp=sharing">linear Methods for regression</a> secciones. 3.1, 3.2.</p>
<p>Comente en Disqus</p>
</div>
<div id="terminos-clave" class="section level3">
<h3>Términos clave</h3>
<ul>
<li><p>Distribución <strong>t</strong></p></li>
<li><p><em>Standard Error</em> <strong>SE</strong></p></li>
<li><p>Resiadual Standard Error <strong>RSE</strong></p></li>
<li><p><em>Residual Sum of squares</em> <strong>RSS</strong></p></li>
</ul>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>La validez de esta definición bajo el supuesto de que los errores <span class="math inline">\(\epsilon_i\)</span> no estan correlacionados con <span class="math inline">\(\sigma^2\)</span><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Donde el p-value indica que podemos rechazar la hipótesis nula de que <span class="math inline">\(\beta=0\)</span><a href="#fnref2">↩</a></p></li>
</ol>
</div>
