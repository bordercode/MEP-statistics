---
title: "RL-Modelo"
author: "José Luis Manzanarees Rivera"
date: 2019-01-15T21:11:11-05:00
categories: ["R"]
tags: ["Regresión Lineal", "MCO", "regression"]
mathjax : true
menu:
  main:
    name: RL-Modelo
    weight: 5
---


```{r set-global-options, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = FALSE)                     

```



```{r silent-packages, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
library(tidyverse)
library(wooldridge)
library(ISLR)
```


## Formalización del modelo 

En términos matemáticos  podemos describir la relación entre las variables del modelo con la expresión siguiente:

\begin{align}
Y \approx \beta_0 + \beta_1 X
(\#eq:align)
\end{align}

Una vez que hemos estimado los parámetros del modelo podemos usarlos para hacer la predicción de $\hat y$ 


\begin{align}
\hat y= \hat \beta_0 + \hat \beta_1 x
(\#eq:mod)
\end{align}

![](/img/lm4.jpg)


Note que la diferencia entre la linea de regresión y cada observación (lineas grises) da cuenta del error de predicción.

$$e_i=y_i - \hat y_i$$
El modelo de regresión toma la suma al cuadrado de estos errores para determinar la  estimación de la linea de mejor ajuste.

Suponemos una serie de axiomas que conforman el fundamento teórico de esta modelo a partir del **Teorema de Gasuss Markov**. 

Suponemos un valor esperado para el término aleatorio (*random noise*) $E(\epsilon)=0$. Esto es, suponemos que la distribución de estos factores no observados, en promedio tienen media cero.


#### Supuesto de Media condicional cero.

Sean $x$ y $\epsilon$ variables  aleatorias. 

Suponemos que el valor promedio de las características no observadas no depende del valor particular que tome $x$  $$E(\epsilon|x)=E(\epsilon)=0$$

El valor esperado de las características no observadas, es independiente de $x$  y en términos promedio es cero. 

Definición: 

*Residual Sum of Squares* **RSS**.


$$RSS=e_1^2 +e_2^2+...+e_n^2$$
\begin{align}
RSS= (y_1- \hat \beta_0 - \hat \beta_1 x_1)^2 + (y_2- \hat \beta_0 - \hat \beta_1 x_2)^2+...+(y_n- \hat \beta_0 - \hat \beta_1 x_n)^2
(\#eq:RSS)
\end{align}

![](/img/rss1.jpg)
El enfoque de Mínimos Cuadrados Ordinarios **MCO** (Ordinary Least Squares OLS por sus siglas en inglés), selecciona los parámetros $\hat \beta_0 , \hat \beta_1$ que minimizan la **RSS**. 

#### Coeficientes acorde con el criterio MCO.


\begin{align}
\hat \beta_1 =\frac{ \sum_{i=1}^{n} (x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n} (x_i-\bar{x})^2},
(\#eq:beta)
\end{align}


El parámetro $\hat \beta_1$ es el cociente  de la covarianza  de $(x,y)$ y la varianza de $x$.  Dividir por $\frac{1}{n}$ ambos factores no hace diferencia alguna.     

$$\hat \beta_0 =\bar y- \hat \beta_1 \bar{x}$$
Donde $$\bar{y}\equiv\frac{1}{n} \sum_{i=1}^{n} y_i$$ y  $$\bar{x} \equiv \frac{1}{n} \sum_{i=1}^{n} x_i$$

Note por la definición  que si $x$ e $y$ tienen correlación positiva, $\Rightarrow \hat \beta_1>0$ y si $\sum_{i=1}^{n} (x_i-\bar{x})(y_i-\bar{y})<0 \Rightarrow \hat \beta_1<0$
dado que $\sigma^2$ tiene un min val=0, ie. $\sigma^2$ nunca es negativo$

Considere la siguiente representación del modelo lineal a partir del valor esperado y con los supuestos $E(\epsilon)=0$ e independencia entre la parte aleatoria del modelo  y las variables explicativas:  y  $cov(x,\epsilon)=E(x \epsilon)=0$

\begin{align}
E(y-\beta_0-\beta_1 x)=0
(\#eq:ve)
\end{align}



\begin{align}
E [x(y-\beta_0-\beta_1 x)]=0
(\#eq:ve1)
\end{align}


Los parámetros muestrales correspondientes

\begin{align}
\frac{1}{n}\sum_{i=1}^{n} (y_i-\hat \beta_0- \hat \beta_1 x_i) =0
(\#eq:ve3)
\end{align}


\begin{align}
\frac{1}{n} \sum_{i=1}^{n} x_i(y_i-\hat \beta_0- \hat \beta_1 x_i)=0
(\#eq:ve4)
\end{align}

Ecuaciones \@ref(eq:ve3) y \@ref(eq:ve4) son las condiciones de primer orden a resolver acorde con los principios de optimización.

A partir de las propiedades de suma estas ecuaciones se pueden reescribir:

\begin{align}
\bar{y}=\hat \beta_0- \hat \beta_1 \bar{x} 
(\#eq:ve5)
\end{align}

Reescribiendo $\hat \beta_0$  y  $\hat \beta_1$  en términos de $\bar{y}$ y $\bar{x}$ tenemos: 

\begin{align}
\hat \beta_0= \bar{y} - \hat \beta_1 \bar {x}=0
(\#eq:ve6)
\end{align}


Sustituyendo \@ref(eq:ve6) en \@ref(eq:ve4) tenemos

$$\sum_{i=1}^{n} x_i [ y_i-(\bar y- \beta_1 \bar{x})- \hat \beta_1 x_i]=0$$




Reordenando tenemos: 

$$\sum_{i=1}^{n}x_i(y_i-\bar{y})= \hat \beta_1  \sum_{i=1}^{n} x_i(x_i-\bar {x})$$ 


Considerando propiedades de suma tenemos:

$$\sum_{i=1}^{n} x_i(y_i- \bar{y})= \sum_{i=1}^{n} (x_i- \bar{x})(y_i- \bar{y}) , \sum_{i=1}^{n} x_i(x_i- \bar{x})=\sum_{i=1}^{n} (x_i- \bar{x})^2$$
Si $\sum_{i=1}^{n} (x_i- \bar{x})^2>0$ lo cual se cumple cuando **NO** todos los valores de la muestra son iguales, entonces:


\begin{align}
\hat \beta_1=  \frac{\sum_{i=1}^{n} (x_i- \bar{x})(y_i- \bar{y}) }{\sum_{i=1}^{n} (x_i- \bar{x})^2}
(\#eq:ve7)
\end{align}




Considerando el **supuesto de Media condicional cero** $E(\epsilon|x)=0$  y representando el valor esperado de \@ref(eq:mod) condicional en $x$ tenemos una función lineal de $x$: 

\begin{align}
E(y|x)= \beta_0+ \beta_1 X 
(\#eq:expval)
\end{align} 

La siguiente gráfica muestra esta idea para la función lineal  $\beta_0+\beta_1 x$ con la distribución de los valores de $y$ centrados en  $E(y|x)$

![](/img/lm6.jpg){width=400px}

Lo que significa que **un incremento de una unidad en $x$ cambia el valor esperado de $y$ por el monto denotado $\hat \beta_1$**, para cualquier valor dado de $x$, $y$ que está centrado alrededor de $E(y|x)$. 

En términos de la ecuación lineal el estimado de la pendiente es: 
$$\hat \beta_1= \frac{\Delta \hat y}{\Delta  x}$$ 
$$\Delta \hat y=\hat \beta_1 \Delta  x$$

En la siguiente figura se presenta ésta idea con una muestra teórica de valores aleatorios para $x$ y $y$.  

El panel a) muestra en linea roja la verdadera relación en entre $x$ y $y$, la linea azul es la linea de regresión obtenidad por MCO que se basa en los datos observados (scatter points). 

En panel b) se incluyen las lineas de regresión para  10 modelos con muestras aleatorias en la población de $x$, vemos que cada modelo permite generar una línea distinta si bien,  en *promedio* estas siguen la trayectoria de la linea de regresión poblacional (roja).

En el panel c) Observamos el efecto del criterio de minimos cuadrados  con la obtensión del *RSS* de menor valor para los parámetros $\hat  \beta_0$  y $\hat \beta_1$


![](/img/lm5.jpg)

**Ejemplo 1**

Considerando el ejemplo  de la relación entre salario y años de educación $log(wage)=\beta_0 +\beta_1 educ+ \epsilon$  

Con el logaritmo de salario (**wage** en dólares por hora) para medir el cambio porcentual ante el incremento de un año adicional de educación  con la variable **educ** que se registra en años.

Recordamos que  $\epsilon$ integra un conjunto de variables que se asumen constantes como experiencia, habilidades, etc., Y estas tienen una distribución representada por el valor esperado normalizado en cero $E(\epsilon)=0$. (algunas personas tienen más habilidad natural que otras, más o menos experiencia, considerar el supuesto de la distribución con media cero es consistente con este hecho empírico).

La gráfica siguiente muestra la linea de regresión (rojo) para las variables salarios y educación con las observaciones (azul) como un scatter plot. 


```{r, , echo=FALSE}
data(wage1)
theme_set(theme_light())

ggplot(wage1,aes(educ,lwage))+
geom_point(shape=1,color="blue")+
stat_smooth(method=lm, se=FALSE, colour="red", size=.2)+
labs(title="Log Salario v.s Educación", x="Años de educación", y="Salario por hora (USD)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+ 
  scale_x_continuous(breaks = c(0, 6, 12,18))
```


Notamos una relación positiva y a medida que la persona tiene más años de educación en promedio percibe un mayor salario.

Tenemos una  linea de regresión obtenida bajo el criterio de MCO y observamos una distancia entre la linea de regresión y las observaciones, sin embargo sabemos que la linea de regresión minimiza esa distancia.



Considerando los parámetros estimados para este ejemplo sobre la relación salario y años de educación tenemos que $\hat \beta_0=0.583773$  y $\hat \beta_1=0.082744$

Lo que implica que un año adicional de educación se relaciona con un incremento del 8.2% en el salario por hora percibido.


**Nota** sobre el uso de logaritmos en la forma funcional del modelo de regresión lineal.

![](/img/logs.jpg)

```{r, echo=FALSE}
data(wage1)

log_wage_model <- lm(lwage ~ educ, data = wage1)
summary(log_wage_model)
```


#### Ejemplo 2

Consideremos ahora la base de datos: *Height and weight of school children* de Lewis, T., & Taylor, L.R. (1967) en el estudio introduction to Experimental Ecology, que contiene 236 observaciones para 5 variables en una muestra de niños en edades entre 11 A 17 años, para estudiar la relación  entre dos variables la altura y la edad. En términos teóricos se ha demostrado que entre la población munidal  se tiene una estrecha relación entre estas variables. 


```{r,, echo=FALSE }


heightweight<-readRDS("heightweight.rds")

theme_set(theme_light())

heightweight%>%
  mutate(sex=ifelse(sex=="f","Mujer","Hombre"))%>%
  ggplot(aes(x=ageYear, y=heightIn, colour=sex)) +
geom_point(alpha=.5) +
scale_colour_brewer(palette="Set1")+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+
  labs(x="Edad en años", y="Estatura (pulgadas)"  )+
  labs(colour="Sexo")
```  

```{r, echo=FALSE}

heightweight<-readRDS("heightweight.rds")

lm( heightIn~ ageYear, data = heightweight)%>%
summary()

M<-heightweight%>%
  filter(sex=="f")

lm( heightIn~ ageYear, data = M)%>%
summary()

H<-heightweight%>%
  filter(sex=="m")

lm( heightIn~ ageYear, data = H)%>%
summary()
```

Notamos  un efecto positivo, que es de mayor magnitud para los niños. Con un incremento de $\hat \beta_1= 2.03$ pulgadas por un año adicional. Mientras el incremento para el sexo femenino es ligeramente inferior. $\hat \beta_1=1.2$

Note además que el modelo se estima con las varaibles en niveles por lo que la interpretación se hace considerando las unidades de cada variable en este caso edad en años y estatura en pulgadas.

#### Ejemplo 3

Considermos ahora una situación en la que la variable dependiente es ventas (monto expresado en unidad monetaria ej. miles de dólares). Y las variables independientes corresponden a gastos en publicidad para tres medios:  t.v.,  newspapers,  radio. La muestra contiene 200 observaciones para las variables: Y=ventas,  x=gasto en publicidad dirigido a tv. y corresponden a 200 puntos de venta.

El modelo de regresión siguiente muestra la relación entre la variable ventas y los gastos en publicidad para el medio t.v. (gasto expresado en miles de USD y y ventas en unidades). 



```{r, echo=FALSE}

ad<-read.csv("Advertising.csv")

 p<- ggplot(ad,aes(x=TV, y=sales)) +
geom_point(alpha=.5) +
scale_colour_brewer(palette="Set1")+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+
  labs(x="Gastos en TV (Miles USD)", y="Ventas (Miles unidades)"  )+
  labs(colour="Sexo")
p

lm( sales~ TV, data = ad)%>%
summary()

```

Los parámetros estimados del modelo indican que un incremento de una unidad adicional  (en este caso  un incremento de $\$ 1000$) en la variable gasto en publicidad en TV se asocia con un incremento de 47 unidades en la variable ventas $\hat \beta_1=0.047537$


#### Ejemplo 4

Consideremos ahora la relación entre el Sueldo que perciben los CEO's (Chief Executive Officer) y el indicador de desempeño financiero *return on equity* **roe** este es un indicador clásico que es utilizado como *proxy* para medir el desempeño de un CEO. La muestra contiene 209 observaciones y  12 variables con información financiera publicadas por un estudio de *Businessweek* de Mayo 6, 1991. 

La variable dependiente es el Sueldo (expresado en miles USD). En términos teóricos se supone que existe una relación positiva entre el Sueldo que un CEO percibe e indicadores de desempeño de la compañia, en este sentido el    **roe** es una variable que recoge el desempeño financiero (variable que se encuentra expresada en porcentaje).

Estimaremos ahora el modelo de regresión lineal $$y=\hat \beta_0 + \hat \beta_1 x+\epsilon$$  $$salario=\beta_0 + \hat \beta_1 roe+\epsilon$$  para conocer si la hipótesis sobre la relación entre las variables se cumple y en su caso la magnitud de los parámetros $\hat \beta_0, \hat \beta_1$

```{r, echo=FALSE}

library(wooldridge)
data(ceosal1)
str(ceosal1)

summary(ceosal1$salary)
summary(ceosal1$roe)

lm( salary~ roe, data = ceosal1)%>%
summary()

```
Como es costrumbre en primera instancia exploramos la estructura de los datos. Tenemos 209 observaciones, 12 variables.  

En segundo lugar analizamos las estadísticas descriptivas. 
Para la variable Sueldo tenemos  una media de $\$1,281,000$ usd anuales, un mínimo de $\$223,000$ y un máximo de $\$14,822,000$. El rendimiento del capital promedio es $17.18\%$, máximo de $56.30\%$ y mínimo de $.50\%$

En tercer lugar note por el  parámetro $\hat \beta_1$ que hay una relación positiva ente Sueldo del CEO y el roe de la compañia, con $\hat \beta_0=963.19$ lo que implica que si el ROE es cero, la predicción del sueldo es $\$963,190$ y la pendiente   $\hat \beta_1=18.50$. Así $\Delta x=1\%\Rightarrow \Delta y=\$ 18,500$ En otras palabras ante **un incremento de 1% en el roe**, en promedio, el sueldo del CEO $i$ cambia  en  $\$ 18,500$  usd anuales.

La siguiente gráfica muestra estas relaciones distinguiendo por dos escenarios de interés  (con variables categóricas)  

```{r, echo=FALSE}

library(wooldridge)
data(ceosal1)
theme_set(theme_light())
summary(ceosal1$salary)
csa2<-ceosal1%>%
mutate(ventas=as.factor(ifelse(sales>7177,"High","Low")),
consprod=as.factor(ifelse(consprod==1,"Consumo","No")))


ggplot(csa2,aes(roe,salary,color=ventas))+
  geom_point(shape=1,color="darkgreen")+
  geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+
  labs(x="Rendimiento sobre capital (%)", y="Sueldo (Miles USD)" )

ggplot(csa2,aes(roe,salary,color=consprod))+
  geom_point(shape=1,color="darkgreen")+
  geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+
  scale_colour_brewer(palette="Set1")+
  labs(color="Empresa")+
  labs(x="Rendimiento sobre capital (%)", y="Sueldo (Miles USD)" )
  

```

## Actividad 3


#### Ejercicio 1 

Considere el siguiente escenario sobre procesos electorales. Sea una [muestra](https://drive.google.com/file/d/1lzbPJYbvk2C7uRk8JMB0RT3tvpoTl4X8/view?usp=sharing) de 173 resultados de votaciones distritales en un proceso entre dos partidos. La variable dependiente es el porcentaje de voto que recibió el candidato en la elección y la variable independiente es la proporción del gasto total de campaña correspondiente al candidato. Estudio de  M. Barone and G. Ujifusa, The Almanac of American Politics, 1992.


a) Estime el modelo de regresión y determine $\hat \beta_0, \hat \beta_1$.

b) ¿Cuál es el efecto en el porcentaje del voto ante un incremento de $1\%$ en los gastos de campaña del candidato. 

c) Estime el porcentaje del voto recibido si la proporción en gasto de campaña es de $62\%$   $\Delta \hat voto= \hat \beta_1  \Delta gasto$


```{r, eval=FALSE, echo=FALSE}
theme_set(theme_light())


vote1<-readRDS("vote1.rds")
data(vote1)
str(vote1)

lm(voteA~shareA,data=vote1)%>%
summary()

351.687/(351.687+50.532)
```

```{r,echo=FALSE}
vote1<-readRDS("vote1.rds")%>%
ggplot(aes(shareA,voteA))+
  geom_point(shape=1)+
  geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+
  labs(x="Gastos en campaña (%)", y="Voto (%)")
vote1
```



## Tarea.

Leer sección *The Effects of Changing Units of Measurement on OLS Statistics*  y sección: *Incorporating Nonlinearities in Simple Regression* en Wooldridge (pags. 40-44)

Como interpretamos una modelo de regresión cuya variable dependiente se expresa mediante una transformación logarítmica? 

Qué interpretación tiene el coeficiente $\hat \beta_1$ en el modelo en logarítmos para las variables dependiente y explicativa. 


Comente en Disqus.

### Términos clave

+ Coeficiente de la pendiente $\hat \beta_1$

+ coeficiente de intercepto $\hat \beta_0$
