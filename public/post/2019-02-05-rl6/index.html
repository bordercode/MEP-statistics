<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>RL-Diagnóstico</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.54.0" />
	<meta property="og:title" content="RL-Diagnóstico" />
<meta property="og:description" content="Análisis de los supuestos y pruebas de diagnóstico del modelo.I Heterocedsticidad.Uno de los supuestos principales del Modelo de Regresión Lineal MRL es que los errores tiene la misma varianza, lo que se conoce como homocedasticidad, \[E(\epsilon|x)=E(\epsilon)=0\] \[var(\epsilon|x)=\sigma^2\]
Cuando el supuesto no se cumple tenemos el problema denominado Heterocedasticidad.
¿Cuáles son las consecuencias del problema de Heterocedasticidad?
Los parámetros estimados ya no se consideran BLUE (Best Linear Unbiased Estimators supuestos del teorema Gauss-Markov)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2019-02-05-rl6/" />
<meta property="article:published_time" content="2019-02-05T21:11:11-05:00"/>
<meta property="article:modified_time" content="2019-02-05T21:11:11-05:00"/>

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-124338825-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="Estadística II" rel="home">
				<div class="logo__title">Estadística II</div>
				<div class="logo__tagline">Semestre II MEP 2019</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">Maestría en estudios de población</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/syllabus/">Syllabus</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2015-07-23-rl/">Regresion Lineal</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-01-11-rl2/">RL-Simple</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-01-15-rl3/">RL-Modelo</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-01-25-rl4/">RL-Hipótesis</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-01-25-rl5/">RL-Muiltiple</a>
		</li>
		<li class="menu__item menu__item--active">
			<a class="menu__link" href="/post/2019-02-05-rl6/">RL-Diagnóstico</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-20-01-rl7-models/">RL-Multiple Cross-Section</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-02-24-pca/">PCA</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-02-25-logistic/">Logistic R</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-04-15-logistic2/">Logistic2 R</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-04-16-logistic3/">Logistic3 R</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2019-04-19-clustering_knn/">Clustering</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/recursos-adicionales/">Recursos Adicionales</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/2018-12-30-ejercicios/">Ejercicios</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">RL-Diagnóstico</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 16 16"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
	<time class="meta__text" datetime="2019-02-05T21:11:11">February 05, 2019</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/r" rel="category">R</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			


<div id="analisis-de-los-supuestos-y-pruebas-de-diagnostico-del-modelo." class="section level2">
<h2>Análisis de los supuestos y pruebas de diagnóstico del modelo.</h2>
<div id="i-heterocedsticidad." class="section level3">
<h3>I Heterocedsticidad.</h3>
<p>Uno de los supuestos principales del Modelo de Regresión Lineal <strong>MRL</strong> es que los errores tiene la misma varianza, lo que se conoce como <strong>homocedasticidad</strong>, <span class="math display">\[E(\epsilon|x)=E(\epsilon)=0\]</span> <span class="math display">\[var(\epsilon|x)=\sigma^2\]</span></p>
<p>Cuando el supuesto no se cumple tenemos el problema denominado <strong>Heterocedasticidad</strong>.</p>
<p>¿Cuáles son las consecuencias del problema de Heterocedasticidad?</p>
<p>Los parámetros estimados ya no se consideran <strong>BLUE</strong> (Best <strong>L</strong>inear <strong>U</strong>nbiased <strong>E</strong>stimators supuestos del teorema Gauss-Markov). Los errores estándard estimados son incorrectos, lo que afecta la construcción de los intervalos de confianza.</p>
<p><strong>Ya no son válidas las pruebas de hipótesis</strong> sobre los parámetros, los estadísticos <strong>t</strong> y <strong>F</strong> ya no son válidos.</p>
<p>Note que <strong>este problema no causa que los estimados sean seasgados (<em>unbiased</em>), sin embargo, </strong>este problema se traduce en que los parámetros ya no son los de menor varianza** entre los estimados insesgados (la B de <em>Best</em> en BLUE ya no se cumple, es decir hay otro estimador posible con menor varianza).</p>
<p>El primer paso, es detectar el problema, para esta tarea usaremos la prueba Breusch-Pagan en dos especificaciones cuyos resultados son equivalentes:</p>
<ul>
<li>Breusch-Pagan: Una prueba que detecta el problema de heterocedasticidad en un modelo de regresión usando una distribución Pearson (<span class="math inline">\(\chi^2\)</span>) (al observar si la varianza de los errores depende de los valores que toman las variables independientes).</li>
</ul>
<p>La prueba plantea como <span class="math inline">\(H_0: Homocedasticidad\)</span> vs. <span class="math inline">\(Ha: Heterocedasticidad\)</span></p>
<div id="ejemplo-1" class="section level4">
<h4>Ejemplo 1</h4>
<p>Analizaremos el modelo que relaciona esperanza de vida con <em>gdp</em> y tasa de mortalidad infantil para 198 paises.</p>
<ul>
<li><p>Primero estimamos el modelo.</p></li>
<li><p>Hacemos una diagnóstico gráfico de los residuales para detectar el patrón consistente con el problema de heterocedasticidad.</p></li>
<li><p>Enseguida aplicamos la prueba <strong>Breusch-Pagan</strong> para hacer una valoración formal.</p></li>
</ul>
<div id="heterocedasticidad-diagnostico-grafico." class="section level5">
<h5>Heterocedasticidad Diagnóstico gráfico.</h5>
<p>Graficar Rediduales vs <span class="math inline">\(\hat y\)</span> en un modelo múltiple o bien residuales vs. variable independiente</p>
<div class="figure">
<img src="/img/heteroc.jpg" />

</div>
<p>Note el patrón creciente en los residuales (las lineas azules muestran la tenencia en las dispersión de los residuales) síntoma característico del problema de heterocedasticidad.</p>
</div>
<div id="a-scatter-plot-de-residuales-contra-cada-regresor." class="section level5">
<h5>a) Scatter Plot de residuales contra cada regresor.</h5>
<p>Si el supuesto se cumple tendremos una gráfica con observaciones dispersas sin ningún patrón específico. Indicando residuales no correlacionados con los regresores.</p>
<p>A continuación observe 2 violaciones de los supuestos del modelo de regresión lineal que deben atenderse para obtener parámetros válidos, útiles para hacer inferencia. Panel a) relación no lineal, Panel b) Heterocedasticidad.</p>
<div class="figure">
<img src="/img/resid.jpg" />

</div>
<p>Note en la gráfica b) se observa evidencia de heterocedasticidad, mientras en la gráfica a) se observa evidencia de una relación no lineal. Esta puede resolverse con la trasformación de los regresores (inclusión de término cuadrático, transformación Box-Cox,etc,.)</p>
<p><strong>Ejemplo</strong> Obtención de residuales para diagnóstico gráfico. Considere el ejemplo del modelo sobre relación de años de esperanza de vida y características poblacionales para una muestra de 194 paises.</p>
<pre class="r"><code>library(estimatr)

nt&lt;-readRDS(&quot;Nations2a.rds&quot;)%&gt;%
  mutate(region=fct_reorder(region,life))%&gt;%
  select(life,gdp, chldmort)
  
nt&lt;-na.omit(nt)

model&lt;-lm(life~gdp+chldmort, data=nt)
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = life ~ gdp + chldmort, data = nt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.5376  -1.7116   0.5221   2.1838   6.7201 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 74.601145   0.525934 141.845  &lt; 2e-16 ***
## gdp          0.124550   0.021533   5.784 3.29e-08 ***
## chldmort    -0.157475   0.005594 -28.151  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.396 on 175 degrees of freedom
## Multiple R-squared:  0.8856, Adjusted R-squared:  0.8843 
## F-statistic: 677.3 on 2 and 175 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>nt$predicted &lt;- predict(model)   
nt$residuals &lt;- residuals(model) 

ggplot(nt, aes(chldmort, life)) +
  geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;lightgrey&quot;) +
  geom_segment(aes(xend = chldmort, yend = predicted), alpha = .2) +
geom_point(aes(color = abs(residuals), size = abs(residuals)))+
  scale_color_continuous(low = &quot;black&quot;, high = &quot;red&quot;) +
  guides(color = FALSE, size = FALSE) +
  theme_bw()</code></pre>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p><strong>Método alternativo</strong>. Directamente es posible obtener el diagnóstico gráfico de residuales posterior a la estimación del modelo. Dos gráficas son de interés</p>
</div>
<div id="grafica-residuals-vs.fitted-deteccion-de-heterocedasticidad" class="section level5">
<h5>Gráfica Residuals vs. Fitted (detección de heterocedasticidad)</h5>
<p>Residuales vs. <span class="math inline">\(\hat y\)</span>.</p>
<p>Una distribución aleatoria de los residuales alrededor de la linea de tendencia (linea roja) indica homocedasticidad (linea roja recta).</p>
<p>Adicionalmente esta gráfica nos permite detectar si la relación no es lineal entre variable dependiente e independiente.(ej. una linea roja con forma de parábola).</p>
<pre class="r"><code>library(estimatr)

nt&lt;-readRDS(&quot;Nations2a.rds&quot;)%&gt;%
  mutate(region=fct_reorder(region,life))

model&lt;-lm(life~gdp+chldmort, data=nt)
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = life ~ gdp + chldmort, data = nt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.5376  -1.7116   0.5221   2.1838   6.7201 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 74.601145   0.525934 141.845  &lt; 2e-16 ***
## gdp          0.124550   0.021533   5.784 3.29e-08 ***
## chldmort    -0.157475   0.005594 -28.151  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.396 on 175 degrees of freedom
##   (16 observations deleted due to missingness)
## Multiple R-squared:  0.8856, Adjusted R-squared:  0.8843 
## F-statistic: 677.3 on 2 and 175 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(model, which=c(1,1))</code></pre>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="grafica-scale-location-deteccion-de-heterocedasticidad." class="section level5">
<h5>Gráfica Scale-Location (detección de heterocedasticidad).</h5>
<p><em>Scale-location</em> o <em>spread location plot</em> que mide la dispersión de los residuales y permite detectar así el problema de <strong>heterocedasticidad</strong>.</p>
<p>Nuevamente una linea recta con residuales dispersos de manera aleatoria es una indicación de que se cumple la condicion de varianza constante y no hay problema de heterocedasticidad.</p>
<p>En el caso particular el patrón observado presenta una dispersón ligeramente creciente consistente con el problema de heterocedasticidad.</p>
<pre class="r"><code>library(estimatr)

nt&lt;-readRDS(&quot;Nations2a.rds&quot;)%&gt;%
  mutate(region=fct_reorder(region,life))

model&lt;-lm(life~gdp+chldmort, data=nt)
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = life ~ gdp + chldmort, data = nt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.5376  -1.7116   0.5221   2.1838   6.7201 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 74.601145   0.525934 141.845  &lt; 2e-16 ***
## gdp          0.124550   0.021533   5.784 3.29e-08 ***
## chldmort    -0.157475   0.005594 -28.151  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.396 on 175 degrees of freedom
##   (16 observations deleted due to missingness)
## Multiple R-squared:  0.8856, Adjusted R-squared:  0.8843 
## F-statistic: 677.3 on 2 and 175 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(model, which=c(1,3))</code></pre>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-4-1.png" width="672" /><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
</div>
</div>
<div id="aplicacion-de-la-prueba-de-breusch-pagan." class="section level4">
<h4>Aplicación de la prueba de Breusch-Pagan.</h4>
<p>A continuación la estimación de la prueba formal Breusch - Pagan para detectar <strong>heterocedasticidad</strong>. recuerde que la prueba tiene <span class="math inline">\(H0: varianza constante\)</span> <span class="math inline">\(Ha: Heterocedasticidad\)</span></p>
<pre><code>## 
## Call:
## lm(formula = life ~ gdp + chldmort, data = nt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.5376  -1.7116   0.5221   2.1838   6.7201 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 74.601145   0.525934 141.845  &lt; 2e-16 ***
## gdp          0.124550   0.021533   5.784 3.29e-08 ***
## chldmort    -0.157475   0.005594 -28.151  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.396 on 175 degrees of freedom
##   (16 observations deleted due to missingness)
## Multiple R-squared:  0.8856, Adjusted R-squared:  0.8843 
## F-statistic: 677.3 on 2 and 175 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##               Data               
##  --------------------------------
##  Response : life 
##  Variables: fitted values of life 
## 
##          Test Summary           
##  -------------------------------
##  DF            =    1 
##  Chi2          =    12.93232 
##  Prob &gt; Chi2   =    0.0003229571</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  model
## BP = 5.8842, df = 1, p-value = 0.01528</code></pre>
<p>Concluimos en este caso que se viola el supuesto de varianza contante en los errores (p-value&lt;0.05), es decir rechazamos <span class="math inline">\(H0:\sigma^2\)</span> constante. (en ambos métodos <em>p-value</em> &lt;.05, ej <span class="math inline">\(p-value_{bptest} = 0.0152\)</span>), <span class="math inline">\(p-value_{lmtest}0.0003\)</span></p>
</div>
<div id="como-atender-el-problema-de-heterocedasticidad" class="section level4">
<h4>¿Cómo atender el problema de Heterocedasticidad?</h4>
<p>Corregir este problema es un asunto empírico que depende en última instancia del problema que estamos analizando.</p>
<p>No obstante el punto fundamental para resolver este problema es identificar con la causa, (i.e la fuente de la variación no constante). Lograr lo anterior implica observar por ejemplo el rango de variación de los regresores. Variables con RI grandes pueden estar vinculadas con la causa.</p>
<p>En este mismo sentido es posible por ejemplo usar una unidad de medida alternativa para la variable de interés por ejemplo en lugar de usar datos en niveles con unidades originales se puede considerar el uso de la variable en términos per cápita, en tasa por cada 100 mil o porcentaje, dependiendo del escenario de análisis.</p>
<p>Una posible solución es aplicar una transformación logarítmica a la variable dependiente.</p>
<p>Un segundo enfoque es estimar el modelo de regresión ponderada. (<em>weighted least squares</em>).</p>
</div>
</div>
<div id="diagnostico-sobre-los-residuales-normalidad-shapiro-wilk-outliers-cooks-d." class="section level3">
<h3>Diagnóstico sobre los residuales: Normalidad (Shapiro-Wilk), outliers (Cook´s D).</h3>
<p>Un supuesto de partida de los residuales es que se distribuyen a corde a la <strong>normal</strong> (Normalidad en los residuales) con media cero varianza constante <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Utilizamos la el qq plot para validar el cumplimiento del supesto de normalidad de <span class="math inline">\(\epsilon\)</span>.</p>
<p>Si los residuales se distribuyen a corde a la normal, se observa una distribución a lo largo de la diagonal.</p>
<div class="figure">
<img src="/img/qqplotN.jpg" />

</div>
<p>Este método nos permite detectar desviaciones del supuesto de distribución normal en los errores especialmente contrastar la simetria de la distribución.</p>
<p>Presenta los cuantiles de la <strong>distribución normal</strong> contra la distribución de los datos estimados. Note que una distribución normal sigue un patrón a lo largo de la diagonal.</p>
<div id="grafica-qq-norm." class="section level4">
<h4>Gráfica QQ norm.</h4>
<pre class="r"><code>library(&quot;car&quot;)

nt&lt;-readRDS(&quot;Nations2a.rds&quot;)%&gt;%
  mutate(region=fct_reorder(region,life))%&gt;%
  select(life,gdp, chldmort)
  nt&lt;-na.omit(nt)

model&lt;-lm(life~gdp+chldmort, data=nt)
nt$residuals &lt;- residuals(model) 
qqPlot(nt$residuals)</code></pre>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>## [1] 45  3</code></pre>
<p>En este caso observa una deviación que indica una distribución cercana a la normal si bien con datos concentrados hacia las colas (<em>fat tails</em>).</p>
<p>Importante considerar la transformación de los datos para atender el problema cuando no se tiene normalidad en los residuales.</p>
<p>Un procedimiento común es la transformación <strong>Box-Cox</strong>. Básicamente buscamos transformar la variable dependiente utilizando un exponente <span class="math inline">\(\lambda\)</span> consistente con el supuesto de normalidad.</p>
<p>La siguiente especificación indica el proceso para determinar el <span class="math inline">\(\lambda\)</span> óptimo a corde con el procedimiento de máxima verosimilitud propuesto por <strong>Box-Cox</strong> <span class="math display">\[y^ \lambda=x \beta +\epsilon\]</span> <span class="math display">\[\Bigg\{\frac{y^{\lambda} -1}{\lambda}, \lambda \neq0 \\
log (y) , \lambda =0 \]</span></p>
<pre class="r"><code>## La implementación en *R* a continuación:
 
library(MASS)

nt&lt;-readRDS(&quot;Nations2a.rds&quot;)%&gt;%
mutate(region=fct_reorder(region,life))

model&lt;-lm(life~gdp+chldmort, data=nt)


r&lt;-residuals(model)

shapiro.test(r)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  r
## W = 0.89176, p-value = 4.359e-10</code></pre>
<pre class="r"><code>bc=boxcox(model,lambda=seq(-3,3))</code></pre>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>lambda=bc$x[which(bc$y==max(bc$y))]

lambda</code></pre>
<pre><code>## [1] 1.545455</code></pre>
<pre class="r"><code>## Una vez que estimamos el parámetro lambda, realizamos la 
## transformación con : var_Trans_box = (y ^ lambda - 1)/lambda</code></pre>
<p>Note la aplicación de la prueba estadística de <strong>Shapiro-Wilk</strong> que tiene como <strong>H0: Normalidad</strong>.</p>
<p>Generalmente las pruebas de hipótesis que conocemos se construyen de tal forma que buscamos rechazar la hipótesis nula, sin embargo en este caso la prueba tiene como <strong>H0: normalidad</strong>, por lo que un <strong>p-value&lt;0.5</strong> implican rechazar <strong>normalidad</strong>.</p>
<p>Entonces con la prueba <strong>Shapiro-Wilk</strong>, no rechazar H0, (ej. p-values grandes) de hecho se traduce en un buen escenario ya que es razonable asumir que los terminos de error se distribuyen a corde a la normal.</p>
<p>En este caso tenemos un <em>p-value</em>=4.359e-10. Rechazamos <strong>H0</strong>, la distribución de los datos no es acorde con la normal.</p>
<p>Para el resultado de la transformación note que tenemos un <span class="math inline">\(\lambda=1.54\)</span> usualmente se considera el valor entero inmediato en este caso 2.</p>
<p>Importante el procedimiento de transformación no garantiza totalmente obtener datos con distribución normal, especialmente si los datos presentan al grado de sesgo.</p>
<p>Conclusión, en este caso particular tenemos tambipen influencia severa de <strong>outliers</strong>. No importa que transformación usemos el tema de ouliers (obs 3, 25, 43 y 45) resulta un “obstáculo”.</p>
<p>En este caso es conveniente atender el tema de outliers y observaciones con infleuncia notable (<em>high leverage obs</em>). A continuación abordamos este tema.</p>
</div>
<div id="residuals-leverage-y-outliers." class="section level4">
<h4>Residuals leverage y outliers.</h4>
<p>Es importante detectar observaciones que tienen influencia importante en la estimación, estas se denominan observaciones con <em>Hight leverage</em></p>
<p>Así mismo es importante controlar por la presencia de <strong>oultilers</strong>, puntos convalores elevados en la predicción dado el valor de <span class="math inline">\({x_i}\)</span>.</p>
<p>Los valores inusualmente altos de <strong>x</strong> (<em>High leverage obs</em>), relativo al resto de observaciones son datos que pudieran tener una influencia especialmente importante en el modelo.</p>
<p>El enfoque gráfico es útil para controlar por obsevaciones que pudieran incluso indicar algún problema en la forma en que se capturó la información.</p>
<p>Note: Contraste entre obs con gran <strong>Leverage</strong> (influencia) vs. <strong>Outliers</strong> (obs para las que el valor de <span class="math inline">\(\hat y\)</span> es relativamente grande dado el valor de <strong>x</strong>)</p>
<div class="figure">
<img src="/img/lev.jpg" />

</div>
<p>El procedimiento para la detección en R implica el cálculo del estadístico conocido como distancia <em>Cook</em>, (propuesto por R. Dennis Cook in 1977) básicamente este indicador permite detectar aquellas observaciones con <em>high leverage</em>. La especificación es&gt;</p>
<p><span class="math display">\[D_i= \frac{\sum_{j=1}^n  (\hat y_{j} -y_{j(i))}) } { p MSE}\]</span> Donde: <span class="math inline">\(\hat y\)</span> Variable estimada</p>
<p><span class="math inline">\(\hat y_{j(i)}\)</span> Variable estimada sin la observación i</p>
<p><strong>MSE</strong>: Error estandar medio .</p>
<p>p: NÚmero de coeficientes en la regressión</p>
<p>El indicador Distancia de Cook, muestra el cambio normalizado de la variable de respuesta dada la eliminación de una observación <em>i</em>.</p>
<p>En segundo lugar una herramienta que es de utilidad para detectar observaciones atípicas <em>outliers</em> en la variable dependiente es la proyección de los residuales <em>Studentized</em> (SR).</p>
<p>Los <strong>SR</strong> (Studentized Residuals), son los residiuales divididos por la su desviación estandar <span class="math inline">\(SR=e/\sqrt{e}\)</span></p>
<p>Note que en este caso (<strong>outliers</strong>), estamos tratando con el valor que toma la variable dependiente (las <span class="math inline">\(\hat y\)</span>). Mientras en el caso de los <em>high leverage</em> points nos referimos únicamente a las observaciones de la variable independiente <strong>x_i</strong>.</p>
<p>Cuando el valor del <strong>SR</strong> supera 3, existe evidencia de la presencia de <em>outliers</em>. La selección del valor de referencia 3 derivado de la distribución de los datos en relación al número de desviaciones estándard (recordar la aplicación de la prueba t-student).</p>
<p>Así mismo en la versión estandarizada <em>Standarized Residuals</em> los residuales divididos por la desviación estándar estimada (El <strong>treshold</strong> recomendado es 2 para este indicador). (ej. <span class="math inline">\(95\%\)</span> de los datos contenidos a 2 desviaciones estándard.).</p>
<p>Note la única diferencia entre el indicador <em>studentize Residuals</em> y <em>Standarized Residuals</em> es que el primero calcula el modelo una vez que se eliminan las observaciones consideradas outliers. Ambos informan el mismo diagnostico indentificando los <strong>outiliers</strong>.</p>
<p>Y recuerde que controlar por estas observaciones pude ser importante para los resultados del modelo a estimar. En última instacia la decisión sobre quitarlos o no es una cuestión empírica qu dependerá del problema analizado.</p>
<p>A continuación el estimado de a) <em>Cook´s distance</em>, b) Studentized y c) standarized residuals y la gráfica conjunta <em>Leverage diagnóstics</em> para mostrar observaciones con high <em>leverage</em> y <em>outliers</em></p>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-8-1.png" width="672" /><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-8-2.png" width="672" /><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-8-3.png" width="672" /><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-8-4.png" width="672" /></p>
<p>La <strong>solución</strong> es remover estas observaciones y reestimar el modelo.</p>
<p><a href="https://drive.google.com/file/d/1zaKc1XWvELsUgZrS32QdpHoM4-w0y7Qx/view?usp=sharing">Lectura Recomendada. ISL Pag. 97-99</a></p>
<p><a href="https://cran.r-project.org/web/packages/olsrr/vignettes/influence_measures.html">Revisar</a></p>
</div>
</div>
<div id="multicolinealidad-y-su-deteccion.-el-indicador-variance-inflation-factor-vif." class="section level3">
<h3>Multicolinealidad y su detección. El indicador: Variance Inflation Factor VIF.</h3>
<p>Este problema se presenta cuando dos o más variables estan relacionadas entre sí.</p>
<p>Cuando el supuesto de independencia de las variables independientes <span class="math inline">\(x_1, x_2,...,x_p\)</span> no se cumple tenemos el problema de <strong>colinearidad</strong></p>
<p>Escenarios que generan Multicolinealidad son:</p>
<ul>
<li><p>La inclusión de <span class="math inline">\(P\)</span> variables dummies en lugar de <span class="math inline">\(p-1\)</span>. Recuerde que el modelo lineal ya incluye un término intercepto ej. <span class="math inline">\(\beta_0\)</span>. Con un término intercepto, una vez que se han definido <span class="math inline">\(p-1\)</span> variables binarias (dummies) el valor de la <span class="math inline">\(p_{-esima}\)</span>variable ya es conocido y puede considerarse redundante si se incluyen <span class="math inline">\(p\)</span> variables binarias.</p></li>
<li><p>La inclusión de variables que estan altamente correlacionadas entre sí. La gráfica siguiente ilustra este aspecto. Panel a) Dos variables sin correlación, panel b) dos variables altamente correlacionadas (correlación positiva).</p></li>
</ul>
<div class="figure">
<img src="/img/multicoli.jpg" />

</div>
<p><strong>Detección:</strong> Observar la matriz de correlación de las variables independientes. Un par de variables con elevada correlación en valor absoluto indica evidencia de la presencia de colinealidad en el modelo de regresión lineal.</p>
<p>Un problema asociado es la presencia de colinealidad entre un grupo de variables, (tres ó mas variables) denominado <strong>Multicolinealidad</strong>. En este caso la información que aportan las variables resulta redundante. Para detectar este problema en lugar de observar la matriz de correlación, es necesario estimar el indicador <strong>VIF</strong> (<em>Variance Inflation Factor</em>).</p>
<p>El valor más pequeño posible es <strong>1</strong> indicando total ausencia de multicolinealidad ya que el <strong>VIF</strong> es el cociente entre la varianza del <span class="math inline">\(\hat \beta\)</span> cuando se estima el modelo con el conjunto de regresores, divido por la varianza de <span class="math inline">\(\hat \beta\)</span> cuando se estima el modelo únicamente con el parámetro.</p>
<p>Como una regla general un valor de <strong>VIF</strong> entre 5 y 10 indica problemas de multicolinealidad.</p>
<p>A continuación un <strong>ejemplo</strong> con el modelo que relaciona el precio de las viviendas con una serie de 14 características, incluidos atributos sobre calidad ambiental para 506 observaciones (census tract). Fuente de base de datos Harrison, D. and Rubinfeld, D.L. Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81–102.</p>
<pre><code>##  [1] &quot;crim&quot;    &quot;zn&quot;      &quot;indus&quot;   &quot;chas&quot;    &quot;nox&quot;     &quot;rm&quot;      &quot;age&quot;    
##  [8] &quot;dis&quot;     &quot;rad&quot;     &quot;tax&quot;     &quot;ptratio&quot; &quot;black&quot;   &quot;lstat&quot;   &quot;medv&quot;</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.595  -2.730  -0.518   1.777  26.199 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
## zn           4.642e-02  1.373e-02   3.382 0.000778 ***
## indus        2.056e-02  6.150e-02   0.334 0.738288    
## chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
## rm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***
## age          6.922e-04  1.321e-02   0.052 0.958229    
## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
## black        9.312e-03  2.686e-03   3.467 0.000573 ***
## lstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.745 on 492 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 
## F-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>##     crim       zn    indus     chas      nox       rm      age      dis 
## 1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 
##      rad      tax  ptratio    black    lstat 
## 7.484496 9.008554 1.799084 1.348521 2.941491</code></pre>
<p>Note el valor elevado de VIF para la variable <em>Tax</em> (monto del impuesto en tasa por cada 10,000 del valor total).</p>
<p><strong>Solución</strong></p>
<p>En el caso de colinealidad entre dos variables la información que aporta una de las variables involucradas en el problema de colinealidad es redundante, por lo que una solución es eliminar una de las variables con alta correlación.</p>
<p>Una segunda aproximación para resolver el problema es incluir una variable que combine las variables correlacionadas (por ejemplo con un índice compuesto).</p>
<p>Para antender el problema de multicolinealidad encontrado en el modelo sobre el valor de vivienda debido a la variable <em>tax</em>, estimamos el modelo sin esta variable y evaluamos nuevamente el indicador VIF.</p>
<pre><code>##  [1] &quot;crim&quot;    &quot;zn&quot;      &quot;indus&quot;   &quot;chas&quot;    &quot;nox&quot;     &quot;rm&quot;      &quot;age&quot;    
##  [8] &quot;dis&quot;     &quot;rad&quot;     &quot;tax&quot;     &quot;ptratio&quot; &quot;black&quot;   &quot;lstat&quot;   &quot;medv&quot;</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ . - tax, data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.1449  -2.9143  -0.5661   1.7438  26.3113 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.463e+01  5.123e+00   6.760 3.92e-11 ***
## crim        -1.067e-01  3.319e-02  -3.216 0.001384 ** 
## zn           3.637e-02  1.351e-02   2.692 0.007354 ** 
## indus       -6.778e-02  5.583e-02  -1.214 0.225317    
## chas         3.029e+00  8.637e-01   3.507 0.000494 ***
## nox         -1.870e+01  3.847e+00  -4.862 1.57e-06 ***
## rm           3.912e+00  4.209e-01   9.294  &lt; 2e-16 ***
## age         -6.054e-04  1.333e-02  -0.045 0.963804    
## dis         -1.488e+00  2.014e-01  -7.390 6.31e-13 ***
## rad          1.346e-01  4.125e-02   3.262 0.001182 ** 
## ptratio     -9.851e-01  1.317e-01  -7.478 3.48e-13 ***
## black        9.546e-03  2.711e-03   3.521 0.000470 ***
## lstat       -5.222e-01  5.121e-02 -10.198  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.792 on 493 degrees of freedom
## Multiple R-squared:  0.735,  Adjusted R-squared:  0.7285 
## F-statistic: 113.9 on 12 and 493 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>##     crim       zn    indus     chas      nox       rm      age      dis 
## 1.791940 2.184240 3.226015 1.058220 4.369271 1.923075 3.098044 3.954446 
##      rad  ptratio    black    lstat 
## 2.837494 1.788839 1.347564 2.940800</code></pre>
<p>Note que el desempeño del modelo en cuanto al estadístico de bondad de ajuste no se ve afectado. modelo2 <span class="math inline">\(R^2=735\)</span> vs. modelo1 <span class="math inline">\(R^2=74\)</span></p>
</div>
<div id="autocorrelacion" class="section level3">
<h3>Autocorrelación</h3>
<p>Note que cuando no se cumple el supuesto de <strong>errores independientes</strong> tenemos el problema de <strong>autocorrelación</strong> Este problema implica que los errores standard <strong>SE</strong> estan subestimados lo que causa que los intervalos de confianza sean más estrechos de lo que deberían ser.</p>
<p>Por ejemplo, recordemos que un intervalo de confianza del <span class="math inline">\(95\%\)</span> indica que existe una probabilidad del <span class="math inline">\(95\%\)</span> de que el parámetro se encuentra en ese rango, sin embargo con el problema de autocorrelación la probabilidad exprezada por un IC al <span class="math inline">\(95\%\)</span> de hecho podria ser menor.</p>
<p>Recordemos además que los <em>p-values</em> asociados al <em>t-statistic</em> para la prueba de hipótesis dependen también de los <strong>SE</strong> por lo que, estos también serán menores a lo que en realidad deberían ser. Lo que puede traducirse en hacer conclusiones equivocadas sobre la significancia de los <span class="math inline">\(\hat \beta\)</span>.</p>
<p>En síntesis, cuando los errores estan correlacionados tendremos un escenario en el que el nivel de confianza en nuestros parámetros está comprometido.</p>
<p>El problema de autocorrelación es común en estructuras de datos como <strong>series de tiempo</strong>, si bien en datos de corte transversal también puede presentarse.</p>
<p>Situaciones que involucran experimentos con personas que tienen la misma dieta, personas que pertenecen a la misma familia o bien que tienen exposición a los mismos factores de riesgo son suceptibles de presentar el problema de autocorrelación en lso residuales.</p>
<p>Una prueba estándar para detectar autocorrelación es el cálculo del estadístico <strong>Durbin-Watson</strong> este plantea como <strong>H0:</strong> no autocorrelación y un estadístico de prueba <span class="math inline">\(DW\approx2\)</span>.</p>
<p><strong>Note</strong> <span class="math inline">\(DW\approx2\)</span> indica que <strong>no hay auto correlación</strong>.</p>
<p>En el siguiente ejemplo consideramos el estudio sobre cambio climático con datos sobre las temperaturas registradas para la región Ártica (variable dependiente <strong>tempN</strong>: Mide la anomalia o desviación del patrón de temperatura media en un periodo de tiempo dado. La unidad de medida es grados. La variable independiente es el año.</p>
<p><a href="https://www.ncdc.noaa.gov/monitoring-references/faq/anomalies.php">Fuente</a>). La base contiene 33 observaciones para el periodo entre 1979-2011.</p>
<div id="ejemplo-1-1" class="section level5">
<h5>Ejemplo 1</h5>
<pre><code>## 
## Call:
## lm(formula = tempN ~ year, data = artico)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.86475 -0.31366  0.00008  0.20602  1.23892 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.159e+02  1.625e+01  -7.137 5.07e-08 ***
## year         5.852e-02  8.143e-03   7.186 4.44e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4454 on 31 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6128 
## F-statistic: 51.64 on 1 and 31 DF,  p-value: 4.438e-08</code></pre>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  modelo
## DW = 2.0917, p-value = 0.5306
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>El modelo indica que la variable independiente <strong>año</strong> es estadísticamente significativa y un incremento de un año se asocia con un incremento promedio de .058°C o bien .58°C por década en la temperatura de la región Ártica, (el dato estimado de NASA es .16°C/década en el mismo perido).</p>
<p>Ahora bien, una vez que realizamos la prueba <strong>Durbin-Watson</strong> para detectar autocorrelación sobre los residuales, notamos que de hecho no se rechaza la hipotesis nula <span class="math inline">\(H0: Autocorrelacion=0\)</span> una señal positiva para la validéz de las pruebas de hipótesis sobre los parámetros estimados.</p>
<p>La siguiente gráfica permite contrastar el escenario de autocorrelación entre residuales para tres diferentes grados de correlación <span class="math inline">\(\rho\)</span> en una serie de residuales hipotética.</p>
<p>Notablemente el panel c) que describe residuales con alto grado de correlación <span class="math inline">\(\rho=.9\)</span> Muestra un patrón de tendencia acentuada entre observaciones adyacentes.</p>
<div class="figure">
<img src="/img/correl.jpg" />

</div>
</div>
<div id="eleccion-del-modelo-mas-adecuado.-criterios-de-informacion-akaike-aic-y-bayesiano-bic." class="section level4">
<h4>Elección del modelo más adecuado. Criterios de información Akaike AIC y Bayesiano BIC.</h4>
<p>En la estructura de regresión lineal múltiple, la inclusión de nuevas variables explicativas en ocaciones puede resultar en modelos con información redundante como hemos visto al tocar el tema de Multicolinealidad, o bien pueden dejarse fuera importantes variabels explicativas.</p>
<p>En términos generales el principio de parsimonia implica <em>ceteris paribus</em> (<em>other thing being equal</em>) que un modelo simple debe ser usado sobre uno de mayor complicación, (si con un modelo sencillo se explica el fenómeno de interés, no necesito crear un modelo con demasiadas variables que al final del día no me aporta más allá de lo necesario para enteder el fenómeno de estudio).</p>
<p>Una vez que hemos validado el cumplimiento de los suspuestos del modelo una manera de seleccionar el modelo adecuado es aplicar un criterio para validar el equilibrio del modelo en términos del principio de parsimonia.</p>
<p>El criterio de información de Akaike, <em>AIC</em> desarrollado por el estadístico Japonés Hirotugu Akaike, es una herramenta útil para este propósito este penaliza la inclusión de variables explicativas en el modelo. Su expresión es: AIC=2P+nlog(RSS/n): Con <strong>P</strong> como el número de regresores en el modelo y <strong>n</strong> el tamaño de muestra.</p>
<p>Note que el <strong>AIC</strong> penaliza la inclusión de <em>k</em> variables adicionales en 2k.</p>
<p>El objetivo es mínimizar el AIC. El modelo con el menor <strong>AIC</strong> es preferible.</p>
<p>Existen otras variantes del AIC como el <strong>BIC</strong>. En el mismo sentido el <em>BIC</em> Bayesian Information criterion, busca contrastar el modelo más adecuado. Tal como en el caso anterior el modelo de menor <strong>BIC</strong> es considerado el más adecuado de entre un conjunto de especificaciones alternativas.</p>
<p>La metodología <strong>stewise regression</strong> consiste en elegir la especificación del modelo con la inclusión de variables que aportan información bajo el principio de parsimonia considerando la minimización del <strong>AIC</strong>. Así la técnica permite la eliminación de variables que cuya aportación a la capacidad explicativa del modelo no es indispensable.</p>
<div id="ejemplo-2" class="section level5">
<h5>Ejemplo 2</h5>
<p>A continuación se presenta la aplicación del criterio de información Akaike <strong>AIC</strong> para el modelo sobre precio de la vivienda en función de sus caracterisitcas incluidos aspectos ambientales. El objetivo es determinar el modelo que minimiza el <strong>AIC</strong>.</p>
<pre><code>##  [1] &quot;crim&quot;    &quot;zn&quot;      &quot;indus&quot;   &quot;chas&quot;    &quot;nox&quot;     &quot;rm&quot;      &quot;age&quot;    
##  [8] &quot;dis&quot;     &quot;rad&quot;     &quot;tax&quot;     &quot;ptratio&quot; &quot;black&quot;   &quot;lstat&quot;   &quot;medv&quot;</code></pre>
<pre><code>## Start:  AIC=1598.59
## medv ~ (crim + zn + indus + chas + nox + rm + age + dis + rad + 
##     tax + ptratio + black + lstat) - tax
## 
##           Df Sum of Sq   RSS    AIC
## - age      1      0.05 11321 1596.6
## - indus    1     33.85 11355 1598.1
## &lt;none&gt;                 11321 1598.6
## - zn       1    166.36 11487 1604.0
## - crim     1    237.53 11559 1607.1
## - rad      1    244.37 11565 1607.4
## - chas     1    282.51 11604 1609.1
## - black    1    284.65 11606 1609.2
## - nox      1    542.78 11864 1620.3
## - dis      1   1254.25 12575 1649.8
## - ptratio  1   1284.10 12605 1651.0
## - rm       1   1983.63 13305 1678.3
## - lstat    1   2388.04 13709 1693.4
## 
## Step:  AIC=1596.59
## medv ~ crim + zn + indus + chas + nox + rm + dis + rad + ptratio + 
##     black + lstat
## 
##           Df Sum of Sq   RSS    AIC
## - indus    1     33.89 11355 1596.1
## &lt;none&gt;                 11321 1596.6
## + age      1      0.05 11321 1598.6
## - zn       1    169.33 11490 1602.1
## - crim     1    237.56 11559 1605.1
## - rad      1    246.72 11568 1605.5
## - chas     1    282.80 11604 1607.1
## - black    1    285.32 11606 1607.2
## - nox      1    587.79 11909 1620.2
## - ptratio  1   1293.79 12615 1649.3
## - dis      1   1365.32 12686 1652.2
## - rm       1   2066.69 13388 1679.4
## - lstat    1   2710.14 14031 1703.2
## 
## Step:  AIC=1596.1
## medv ~ crim + zn + chas + nox + rm + dis + rad + ptratio + black + 
##     lstat
## 
##           Df Sum of Sq   RSS    AIC
## &lt;none&gt;                 11355 1596.1
## + indus    1     33.89 11321 1596.6
## + age      1      0.10 11355 1598.1
## - zn       1    171.14 11526 1601.7
## - rad      1    228.60 11584 1604.2
## - crim     1    229.70 11585 1604.2
## - chas     1    272.67 11628 1606.1
## - black    1    295.78 11651 1607.1
## - nox      1    785.16 12140 1627.9
## - dis      1   1341.37 12696 1650.6
## - ptratio  1   1419.77 12775 1653.7
## - rm       1   2182.57 13538 1683.1
## - lstat    1   2785.28 14140 1705.1</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + 
##     ptratio + black + lstat, data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.2609  -2.9888  -0.5083   1.8041  26.2482 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  34.712342   5.102742   6.803 2.97e-11 ***
## crim         -0.104843   0.033132  -3.164 0.001650 ** 
## zn            0.036634   0.013412   2.731 0.006532 ** 
## chas          2.967868   0.860830   3.448 0.000614 ***
## nox         -20.314416   3.472292  -5.850 8.92e-09 ***
## rm            3.977104   0.407731   9.754  &lt; 2e-16 ***
## dis          -1.429370   0.186922  -7.647 1.08e-13 ***
## rad           0.128761   0.040788   3.157 0.001692 ** 
## ptratio      -1.014914   0.129006  -7.867 2.30e-14 ***
## black         0.009700   0.002701   3.591 0.000363 ***
## lstat        -0.528147   0.047930 -11.019  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.79 on 495 degrees of freedom
## Multiple R-squared:  0.7342, Adjusted R-squared:  0.7288 
## F-statistic: 136.7 on 10 and 495 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="conclusion" class="section level4">
<h4>Conclusión:</h4>
<p>El proceso de diagnóstico post estimación es muy importante, ya que nos permite detectar problemas de especificación que se pueden resolver antes de avanzar con la fase de inferencia. Tal vez sea necesario aplicar transformaciones a los datos o determinar si realmente tenemos una relación lineal entre la variable dependiente y los regresores.</p>
</div>
</div>
<div id="actividad." class="section level3">
<h3>Actividad.</h3>
<p>1.-Observe la siguiente gráfica que relaciona los residuales de un modelo de regresión lineal con los valores de predicción de la variable dependiente <span class="math inline">\(\hat y\)</span>.</p>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>¿Qué podemos concluir sobre el supuesto de homocedasticidad para este modelo?</p>
<p>2.- Considere el siguiente escenario en el que se busca predecir el valor de las viviendas (variable <em>AdjSalePrice</em>) con base en diversos atributos tanto de las casas así como del vecindario en donde se ubican.</p>
<p>La base de datos contiene 22,689 observaciones (viviendas vendidas entre 2014 y 2015) para un total de 22 variables con información para el Condado King (que incluye al ciudad de Seattle, Washington, EUA). Para descripción completa de la base de datos Ver <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">Data dictionary</a></p>
<ol style="list-style-type: lower-alpha">
<li>Estime el modelo de regresión lineal múltiple para la especificación:</li>
</ol>
<p><span class="math display">\[AdjSalePrice=\beta_0+\beta_1 SqFtTotLiving+\beta_2 SqFtLot+\beta_3 Bathrooms +\beta_4 Bedrooms +\beta_5 BldgGrade+\epsilon\]</span> Donde:</p>
<p>AdjSalePrice: Precio de venta ajustado</p>
<p>SqFtTotLiving:Área de construcción en (pies cuadrados).</p>
<p>SqFtLot: Área del terreno (pies cuadrados).</p>
<p>Bathrooms: Número de Baños.</p>
<p>Bedrooms: Número recamaras.</p>
<p>BldgGrade: calificación general dada a la vivienda con base en el sistema de clasificación del condado <em>King</em>.</p>
<p>Interprete el resultado para las variables que son estadisticamente significativas. En qué monto se incrementa el precio ante un aumento de Área de construcción de 1 sqrft adicional? y por 100?</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>¿Qué proporción de la varianza es explicada por el modelo según el coeficiente de determinación?</p></li>
<li><p>Aplique la metodología <em>Stepwise regression</em> y determine la especificación del modelo que minimiza el criterio de información Akaike <strong>AIC</strong>. ¿Qué variables explicativas han sido excluidas del modelo? ¿Cual es el valor que toma el <strong>AIC</strong> para el modelo inicial y el final?</p></li>
<li><p>Estime el modelo en la especificación siguiente:</p></li>
</ol>
<p><span class="math display">\[AdjSalePrice = \beta_0 +\beta_1 SqFtTotLiving + \beta_2 Bathrooms + \beta_3 Bedrooms + \beta_4 BldgGrade + \beta_5 PropertyType + \beta_6 SqFtFinBasement + \beta_7  YrBuilt, +\epsilon\]</span></p>
<p>Donde:</p>
<p>SqFtFinBasement: Superficie sotano terminado (<em>finished basement</em>)</p>
<p>PropertyType: Tipo de propiedad. Variable categórica con tres factores: Multiplex, Single Family y Townhouse.</p>
<pre><code>## &#39;data.frame&#39;:    22689 obs. of  22 variables:
##  $ DocumentDate   : Factor w/ 2560 levels &quot;01/01/2007&quot;,&quot;01/01/2009&quot;,..: 1326 1298 2378 2051 2392 2465 2352 1988 1840 1833 ...
##  $ SalePrice      : int  280000 1000000 745000 425000 240000 349900 327500 347000 220400 437500 ...
##  $ PropertyID     : num  1000102 1200013 1200019 2800016 2800024 ...
##  $ PropertyType   : Factor w/ 3 levels &quot;Multiplex&quot;,&quot;Single Family&quot;,..: 1 2 2 2 2 3 2 2 2 1 ...
##  $ ym             : Factor w/ 113 levels &quot;01/01/2006&quot;,&quot;01/01/2007&quot;,..: 86 51 2 13 28 24 76 42 78 69 ...
##  $ zhvi_px        : int  405100 404400 425600 418400 351600 369800 374300 432100 414800 411100 ...
##  $ zhvi_idx       : num  0.931 0.929 0.978 0.961 0.808 ...
##  $ AdjSalePrice   : num  300805 1076162 761805 442065 297065 ...
##  $ NbrLivingUnits : int  2 1 1 1 1 1 1 1 1 2 ...
##  $ SqFtLot        : int  9373 20156 26036 8618 8620 1012 34465 14659 5324 10585 ...
##  $ SqFtTotLiving  : int  2400 3764 2060 3200 1720 930 1750 1860 990 1980 ...
##  $ SqFtFinBasement: int  0 1452 900 1640 0 0 0 620 0 0 ...
##  $ Bathrooms      : num  3 3.75 1.75 3.75 1.75 1.5 1.5 1.75 1 2 ...
##  $ Bedrooms       : int  6 4 4 5 4 2 3 4 2 4 ...
##  $ BldgGrade      : int  7 10 8 7 7 8 8 7 6 6 ...
##  $ YrBuilt        : int  1991 2005 1947 1966 1948 2008 1961 1963 1930 1924 ...
##  $ YrRenovated    : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ TrafficNoise   : int  0 0 0 0 0 0 0 0 3 0 ...
##  $ LandVal        : int  70000 203000 183000 104000 104000 170000 165000 115000 90000 124000 ...
##  $ ImpsVal        : int  229000 590000 275000 229000 205000 207000 227000 154000 75000 116000 ...
##  $ ZipCode        : int  98002 98166 98166 98168 98168 98144 98178 98178 98032 98055 ...
##  $ NewConstruction: logi  FALSE TRUE FALSE FALSE FALSE TRUE ...</code></pre>
<pre><code>## 
## Call:
## lm(formula = AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
##     Bedrooms + BldgGrade + YrBuilt + PropertyType + SqFtFinBasement, 
##     data = h)
## 
## Coefficients:
##               (Intercept)              SqFtTotLiving  
##                 6.183e+06                  1.985e+02  
##                   SqFtLot                  Bathrooms  
##                 7.933e-02                  4.263e+04  
##                  Bedrooms                  BldgGrade  
##                -5.179e+04                  1.372e+05  
##                   YrBuilt  PropertyTypeSingle Family  
##                -3.568e+03                  2.266e+04  
##     PropertyTypeTownhouse            SqFtFinBasement  
##                 8.476e+04                  7.253e+00</code></pre>
<ol start="5" style="list-style-type: lower-alpha">
<li>¿Cúal es el efecto al incrementar un dormitorio adicional sobre el precio promedio de las viviedas?</li>
</ol>
<p>En la práctica existe una relación positiva entre el valor y la superficie de la vivienda. En este caso tenemos un problema de regresores altamente correlacionados (Bedrooms, bathrooms y SqFtTotLiving), este efecto representa un problema y puede atenderse usando el enfoque para resolver <strong>multicolinealidad</strong> (remover variables que aportan información redundante).</p>
<p>Para ver con claridad el grado de correlación entre estas variables construimos una matriz de correlación para las variables del modelo.</p>
<p><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-17-1.png" width="672" /><img src="/post/2019-02-05-RL6_files/figure-html/unnamed-chunk-17-2.png" width="672" /></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Estime nuevamente el modelo y excluya las variables redundantes (Bathrooms,SqFtTotLiving, SqFtFinBasement). ¿Cuál es el efecto ahora de la variable que registra el número de dormitorios?</li>
</ol>
<div id="omision-de-variables-relevantes-y-efectos-confusores." class="section level4">
<h4>Omisión de Variables relevantes y efectos confusores.</h4>
<p>Mientras con el tema de <strong>multicolinealidad</strong> el problema es la inclusión de variables redundantes, el escenario que causa el problema con las variables confusoras es la <strong>omisión</strong> de posibles variables relevantes.</p>
<p>Consideremos el modelo sobre la relación entre el precio de las viviendas y sus características con datos a escala geográfica de Condado (King).</p>
<p>En la siguiente especificación incluimos una variable denominada <strong>ZipGroup</strong>, es una variable categórica que clasifica las viviendas acorde con el valor promedio de las viviendas del código postal en el que se ubican.</p>
<p>Primero observemos los efectos principales sin la variable que captura la localización.</p>
<p>Note que no se ha incluido una variable que explicitamente capture el efecto de la localización.</p>
<p>La especificación inicial a estimar es:</p>
<p><span class="math display">\[AdjSalePrice=\beta_0+\beta_1 SqFtTotLiving+\beta_2 SqFtLot+\beta_3 Bathrooms +\beta_4 Bedrooms +\beta_5 BldgGrade+\epsilon\]</span></p>
<div id="ejemplo-3" class="section level5">
<h5>Ejemplo 3</h5>
<pre><code>## 
## Call:
## lm(formula = AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
##     Bedrooms + BldgGrade, data = h, na.action = na.omit)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1199508  -118879   -20982    87414  9472982 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -5.219e+05  1.565e+04 -33.349  &lt; 2e-16 ***
## SqFtTotLiving  2.288e+02  3.898e+00  58.699  &lt; 2e-16 ***
## SqFtLot       -6.051e-02  6.118e-02  -0.989    0.323    
## Bathrooms     -1.944e+04  3.625e+03  -5.362 8.32e-08 ***
## Bedrooms      -4.778e+04  2.489e+03 -19.194  &lt; 2e-16 ***
## BldgGrade      1.061e+05  2.396e+03  44.287  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 261200 on 22683 degrees of freedom
## Multiple R-squared:  0.5407, Adjusted R-squared:  0.5406 
## F-statistic:  5340 on 5 and 22683 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note que de forma contra intuitiva la variable que captura la suerficie del terreno tiene un efecto negativo de igual forma la variable # baños, lo cual no es consistente en términos empíricos .</p>
<p>Estos efectos principales contraintuitivos se asociacian probablemente con la omisión de variables explicativas relevantes (<em>confunding variables</em>). Ya que el modelo esta mezclando información de áreas muy heterogéneas.</p>
<p>Ahora vamos a incluir la variable que captura la localización <strong>ZipGroup</strong> (una posible variable confusora) y estimamos el modelo para determinar los efectos principales de variables para validar la relación teórica de causalidad.</p>
<pre class="r"><code>## DATA WRANGLING TO NCLUDE ZIPCODE VARIABLE
## Generar variable para grupo de zip code de barato a caro 1-5
zip_groups &lt;- h %&gt;%
  mutate(resid = residuals(house_lm)) %&gt;%
  group_by(ZipCode) %&gt;%
  summarize(med_resid = median(resid),
            cnt = n()) %&gt;%
  # sort the zip codes by the median residual
  arrange(med_resid) %&gt;%
  mutate(cum_cnt = cumsum(cnt),
         ZipGroup = factor(ntile(cum_cnt, 5)))
h &lt;- h %&gt;%
  left_join(select(zip_groups, ZipCode, ZipGroup), by=&#39;ZipCode&#39;)</code></pre>
<pre><code>## 
## Call:
## lm(formula = AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
##     Bedrooms + BldgGrade + PropertyType + ZipGroup, data = h_zipcode, 
##     na.action = na.omit)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1303632   -94048    -6746    72859  9264307 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               -6.709e+05  2.034e+04 -32.976  &lt; 2e-16 ***
## SqFtTotLiving              2.112e+02  3.677e+00  57.441  &lt; 2e-16 ***
## SqFtLot                    4.692e-01  5.490e-02   8.547  &lt; 2e-16 ***
## Bathrooms                  5.537e+03  3.405e+03   1.626    0.104    
## Bedrooms                  -4.139e+04  2.260e+03 -18.314  &lt; 2e-16 ***
## BldgGrade                  9.893e+04  2.197e+03  45.040  &lt; 2e-16 ***
## PropertyTypeSingle Family  2.113e+04  1.486e+04   1.422    0.155    
## PropertyTypeTownhouse     -7.741e+04  1.615e+04  -4.792 1.66e-06 ***
## ZipGroup2                  5.169e+04  5.188e+03   9.963  &lt; 2e-16 ***
## ZipGroup3                  1.142e+05  4.775e+03  23.922  &lt; 2e-16 ***
## ZipGroup4                  1.783e+05  4.869e+03  36.617  &lt; 2e-16 ***
## ZipGroup5                  3.391e+05  4.693e+03  72.248  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 232000 on 22677 degrees of freedom
## Multiple R-squared:  0.6378, Adjusted R-squared:  0.6377 
## F-statistic:  3631 on 11 and 22677 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note ahora, que tanto la variable superficie como el número de <em>Bathrooms</em> resultan con un efecto principal positivo tal como se espera.</p>
<p>Note en segundo lugar que la inclusión de la variable que captura el efecto de localización es significativa estadísticamente y presenta mayor importancia para las viviendas ubicadas en códigos postales de mayor valor y por ejemplo aquellas propiedades ubicadas en el grupo 5 tiene en promedio un valor mayor en <span class="math inline">\(\$340,000\)</span> respecto a las viviendas en el grupo 1.</p>
<p>El efecto de la variable # domitorios es negativo ya que considerando una casa de la misma superficie contar con más dormitorios implica habitaciones de menor tamaño lo cual impacta el precio negativamente.</p>
</div>
</div>
</div>
<div id="terminos-de-referencia." class="section level3">
<h3>Términos de referencia.</h3>
<p><strong>Homocedasticidad.</strong> Los <span class="math inline">\(\epsilon\)</span> son iid (independientes e identicamente distribuidos) cada uno con media cero y varianza <span class="math inline">\(\sigma^2\)</span> (supuesto de homocedasticidad). Note cuando este supuesto no se cumple tenemos un problema denominado: *heterocedasticidad**.</p>
<p><strong>Autocorrelación</strong></p>
<p><strong>Multicolinealidad</strong></p>
</div>
</div>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 16 16"><path d="M16 9.5c0 .373-.24.74-.5 1l-5 5c-.275.26-.634.5-1 .5-.373 0-.74-.24-1-.5L1 8a2.853 2.853 0 0 1-.7-1C.113 6.55 0 5.973 0 5.6V1.4C0 1.034.134.669.401.401.67.134 1.034 0 1.4 0h4.2c.373 0 .95.113 1.4.3.45.187.732.432 1 .7l7.5 7.502c.26.274.5.632.5.998zM3.5 5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/regresi%C3%B3n-lineal/" rel="tag">Regresión Lineal</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/mco/" rel="tag">MCO</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/regression/" rel="tag">regression</a></li>
	</ul>
</div>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="José Luis Manzanares Rivera avatar" src="/img/aavatar.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About José Luis Manzanares Rivera</span>
	</div>
	<div class="authorbox__description">
		José Luis is a data scientist. He is currently conducting applied research at El Colegio de la Frontera Norte.
	</div>
</div>

<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/2019-02-24-pca/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">PCA</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/2019-02-25-logistic/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Logistic</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "4insight" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/2019-04-19-clustering_knn/">Clasifiación</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2019-04-16-logistic3/">Logistic3</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2019-04-15-logistic2/">Logistic2</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2019-02-25-logistic/">Logistic</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2019-02-05-rl6/">RL-Diagnóstico</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/categories/development">Development</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/r">R</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/basic-elements" title="Basic elements">Basic elements</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/classification" title="Classification">Classification</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/clustering" title="Clustering">Clustering</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/css" title="Css">Css</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/glm" title="Glm">Glm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/html" title="Html">Html</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/knn" title="Knn">Knn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lda" title="Lda">Lda</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/logistic" title="Logistic">Logistic</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/logodds" title="Logodds">Logodds</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mco" title="Mco">Mco</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pca" title="Pca">Pca</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/regresi%c3%b3n-lineal" title="Regresión lineal">Regresión lineal</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/regression" title="Regression">Regression</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/unsupervised-statistical-learning" title="Unsupervised statistical learning">Unsupervised statistical learning</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Estadística II.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>